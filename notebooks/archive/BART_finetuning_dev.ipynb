{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79f7ac2e-f11c-4569-802e-85b024f4430e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# BART Fine-tuning Script Development\n",
    "\n",
    "\n",
    "We will formulate parallel Text Style Transfer as Conditional Generation task and fine-tune the `bart-base` pre-trained model on the Wiki Neutrality Corpus in similar fashion to a Summarization use case. More detail on the modeling approach can be [found here](https://www.notion.so/fastforwardlabs/Modeling-Approach-16576e450a2f4237b595acd926d245f5).\n",
    "\n",
    "In this notebook, we intend to modify the exemplar [Huggingface summarization fine-tuning script](https://github.com/huggingface/transformers/tree/master/examples/pytorch/summarization) to fit our use case, model, dataset, and project scope.\n",
    "\n",
    "**NOTE -** \n",
    "- In order to run the latest version of the example scripts from Hugggingface, you **must install the library from source and install some example-specific requirements**. Details [found here](https://github.com/huggingface/transformers/tree/master/examples#important-note).\n",
    "- In order to get the `scripts/train_job.py` to run as a CML Job, I had to manually run `pip3 install attrs -t /home/cdsw/.local/lib/python3.9/site-packages --no-user`. This allowed me to force an install of the newer attrs package into the .local site-packages, which is needed because runtimes come with an older version (attr) that lives in the /usr/lib directory and gets picked up by default -- throwing an error.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418df6a7-cb26-4797-89e0-8cfd2b446480",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TO DO\n",
    "- need to add automated script that installs HF from source by first cloning the proper tag (as documented in link above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765143bc-a328-4c7e-8b07-4e274d44e342",
   "metadata": {},
   "source": [
    "## Training Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f089757-bb53-44db-ae51-a0f670a32b39",
   "metadata": {},
   "source": [
    "**Default `Trainer` Configs:**\n",
    "- n_epochs: 3\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af81a960-f4f1-4340-838a-96bf49d244e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(60*60*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3194f8be-bf78-4106-b6ce-79c88cc89aff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-1a47b2a41d94>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-1a47b2a41d94>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    watch -n1 nvidia-smi\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Cannot parse: 1:10: watch -n1 nvidia-smi\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cdsw/.local/lib/python3.9/site-packages/lab_black.py\", line 218, in format_cell\n",
      "    formatted_code = _format_code(cell)\n",
      "  File \"/home/cdsw/.local/lib/python3.9/site-packages/lab_black.py\", line 29, in _format_code\n",
      "    return format_str(src_contents=code, mode=FileMode())\n",
      "  File \"src/black/__init__.py\", line 1131, in format_str\n",
      "  File \"src/black/__init__.py\", line 1141, in _format_str_once\n",
      "  File \"src/black/parsing.py\", line 128, in lib2to3_parse\n",
      "black.parsing.InvalidInput: Cannot parse: 1:10: watch -n1 nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "watch -n1 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e6b5bf-e611-4622-b403-ea34385e390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 scripts/run_TST.py \\\n",
    "    --model_name_or_path facebook/bart-base \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_predict \\\n",
    "    --dataset_name \"wnc_one_word\" \\\n",
    "    --output_dir \"./models/bart-tst-oneword\" \\\n",
    "    --overwrite_output_dir \\\n",
    "    --evaluation_strategy \"steps\" \\\n",
    "    --logging_strategy \"steps\" \\\n",
    "    --per_device_train_batch_size=4 \\\n",
    "    --per_device_eval_batch_size=4 \\\n",
    "    --predict_with_generate \\\n",
    "    --load_best_model_at_end=True \\\n",
    "    --max_train_samples=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce52818-e1c6-460d-9c18-a0dc0ff7290e",
   "metadata": {},
   "source": [
    "## Load Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a29c39-cd6e-4230-afb6-680830e84bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq\n",
    "from datasets import load_from_disk, load_metric\n",
    "\n",
    "%load_ext lab_black\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42847815-9158-42d4-a8cb-345a3cabf0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_PATH = \"/home/cdsw/data/processed/WNC_oneword\"\n",
    "MODEL_PATH = \"/home/cdsw/models/bart-tst-oneword-5epoch\"\n",
    "\n",
    "wnc_datasets = load_from_disk(DATASETS_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85918b8-e4f5-43d8-8829-7a6e9c835998",
   "metadata": {},
   "source": [
    "## Evaluation Walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2db09959-f709-40a3-a9e8-12a982b5dc30",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rev_id': ['318427508',\n",
       "  '235640083',\n",
       "  '37561168',\n",
       "  '101665256',\n",
       "  '480248865',\n",
       "  '317239242',\n",
       "  '264200064',\n",
       "  '194952441',\n",
       "  '66405411',\n",
       "  '14497516',\n",
       "  '275953052',\n",
       "  '701211560',\n",
       "  '747113529',\n",
       "  '305605305',\n",
       "  '360725575',\n",
       "  '37134136',\n",
       "  '58108525',\n",
       "  '515090728',\n",
       "  '857485368',\n",
       "  '789013656'],\n",
       " 'source_text': ['in april 2009 a brazilian human rights group, torture never again, awarded the five its chico mendes medal, because their rights had been violated.',\n",
       "  'the 51 day standoff and ensuing murder of 76 men, women, and children--the branch davidians--in waco, texas.',\n",
       "  'mark oaten (born 8 march 1964, watford) is a disgraced liberal democrat politician in the united kingdom, and member of parliament for the winchester constituency.',\n",
       "  'another infamous period of colonisation in ancient times was from the romans.',\n",
       "  'photo sequence of astonishing 2005 chicagoland crash with ryan briscoe.',\n",
       "  'jesus of nazareth is probably mentioned in two passages of the work the antiquities of the jews by the jewish historian josephus, written in the late first century ad.',\n",
       "  'israeli attempts to reduce gazan civilian casualties',\n",
       "  'his 45-year career exceeded that of any other studio head.',\n",
       "  'they see the calling of such councils, for example, by a roman emperor lacking the divine authority as preposterous and assert that the emperors used the councils to exercise their influence to shape and institute christianity to their liking.',\n",
       "  'in the earliest models (earlier than a macintosh ii), all it did was crash silently, without playing any fancy music.',\n",
       "  'elagabulus engaged in frequent homosexual perversions , such as prostituting himself in drag and marrying an enslaved chariot driver.',\n",
       "  'stone soup is an old folk story in which hungry strangers trick the local people of a town into sharing their food.',\n",
       "  'file:donna york.jpg|a barge hauls coal in the louisville and portland canal, the only man-made portion of the ohio river.',\n",
       "  'carwood lipton has appeared on two separate television shows, providing his own commentary in the popular hbo miniseries band of brothers and the inspirational true story of easy company, we stand alone together: the men of easy company.',\n",
       "  'along came a band of missionaries, but they were all horribly massacred.',\n",
       "  'as of january 27, 2006, brokeback mountain had grossed over $46 million in north america and more than $10 million overseas .',\n",
       "  'during the unnecessary horseplay, hamlin fell and severely injured his hand.',\n",
       "  'one elderly jewish man, the wheelchair bound leon klinghoffer, was murdered by the hijackers and thrown overboard.',\n",
       "  'punjab university library has beautiful two-storey building and total area of the building is 102,000 sq.',\n",
       "  'it claims to organize several thousands of scientific conferences a year, using names that are similar to or even the same as real conferences organized by established scientific groups.'],\n",
       " 'target_text': ['in april 2009 a brazilian human rights group, torture never again, awarded the five its chico mendes medal, under the pretext that their rights had been violated.',\n",
       "  'the 51 day standoff and ensuing deaths of 76 men, women, and children--the branch davidians--in waco, texas.',\n",
       "  'mark oaten (born 8 march 1964, watford) is a liberal democrat politician in the united kingdom, and member of parliament for the winchester constituency.',\n",
       "  'another period of colonisation in ancient times was from the romans.',\n",
       "  'photo sequence of 2005 chicagoland crash with ryan briscoe.',\n",
       "  'jesus of nazareth is possibly mentioned in two passages of the work the antiquities of the jews by the jewish historian josephus, written in the late first century ad.',\n",
       "  'israeli efforts to reduce gazan civilian casualties',\n",
       "  'his 45-year career was longer than that of any other studio head.',\n",
       "  'they see the calling of such councils, for example, by a roman emperor lacking the divine authority as groundless and assert that the emperors used the councils to exercise their influence to shape and institute christianity to their liking.',\n",
       "  'in the earliest models (earlier than a macintosh ii), all it did was crash silently, without playing any music.',\n",
       "  'elagabulus engaged in frequent homosexual activities , such as prostituting himself in drag and marrying an enslaved chariot driver.',\n",
       "  'stone soup is an old folk story in which hungry strangers compell the local people of a town into sharing their food.',\n",
       "  'file:donna york.jpg|a barge hauls coal in the louisville and portland canal, the only artificial portion of the ohio river.',\n",
       "  'carwood lipton has appeared on two separate television shows, providing his own commentary in the hbo miniseries band of brothers and the inspirational true story of easy company, we stand alone together: the men of easy company.',\n",
       "  'along came a band of missionaries, but they were all massacred.',\n",
       "  'as of january 27, 2006, brokeback mountain had grossed over $46 million in north america and more than $10 million elsewhere .',\n",
       "  'during the horseplay, hamlin fell and severely injured his hand.',\n",
       "  'one elderly jewish man, the wheelchair -using leon klinghoffer, was murdered by the hijackers and thrown overboard.',\n",
       "  'punjab university library has two-storey building and total area of the building is 102,000 sq.',\n",
       "  'it claims to organize several thousands of scientific conferences a year, using names that are similar to or the same as real conferences organized by established scientific groups.']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = wnc_datasets[\"test\"][:20]\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7356de31-d7e7-4663-8e6b-865576d3152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_source_length = 1024\n",
    "max_target_length = 128\n",
    "\n",
    "\n",
    "def preprocess_function(examples: dict):\n",
    "\n",
    "    inputs = examples[\"source_text\"]\n",
    "    targets = examples[\"target_text\"]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=max_source_length,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            targets,\n",
    "            max_length=max_target_length,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "036e0d99-1760-4896-9334-9da42c88ebf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_inputs = preprocess_function(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1c03346-a0ef-4797-b20d-f7ab24c7f327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 50])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64b79b1-f091-4950-8837-3277bf42bba6",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e866c76c-4e3c-47e3-bea5-4a8cfc8fad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(examples: dict):\n",
    "\n",
    "    model_inputs = preprocess_function(examples)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        model_inputs[\"input_ids\"],\n",
    "        max_length=max_target_length,\n",
    "        min_length=4,\n",
    "        length_penalty=2,\n",
    "        num_beams=4,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fdfad52-638d-48fd-ba34-95a255e68c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in april 2009 a brazilian human rights group, torture never again, awarded the five its chico mendes medal, claiming that their rights had been violated.',\n",
       " 'the 51 day standoff and ensuing killing of 76 men, women, and children--the branch davidians--in waco, texas.',\n",
       " 'mark oaten (born 8 march 1964, watford) is a liberal democrat politician in the united kingdom, and member of parliament for the winchester constituency.',\n",
       " 'another period of colonisation in ancient times was from the romans.',\n",
       " 'photo sequence of 2005 chicagoland crash with ryan briscoe.',\n",
       " 'jesus of nazareth is mentioned in two passages of the work the antiquities of the jews by the jewish historian josephus, written in the late first century ad.',\n",
       " 'israeli aims to reduce gazan civilian casualties',\n",
       " 'his 45-year career exceeded that of any other studio head.',\n",
       " 'they see the calling of such councils, for example, by a roman emperor lacking the divine authority as preposterous and assert that the emperors used the councils to exercise their influence to shape and institute christianity to their liking.',\n",
       " 'in the earliest models (earlier than a macintosh ii), all it did was crash silently, without playing any music.',\n",
       " 'elagabulus engaged in frequent homosexual activities, such as prostituting himself in drag and marrying an enslaved chariot driver.',\n",
       " 'stone soup is an old folk story in which hungry strangers trick the local people of a town into sharing their food.',\n",
       " 'file:donna york.jpg|a barge hauls coal in the louisville and portland canal, the only artificial portion of the ohio river.',\n",
       " 'carwood lipton has appeared on two separate television shows, providing his own commentary in the hbo miniseries band of brothers and the inspirational true story of easy company, we stand alone together: the men of easy country.',\n",
       " 'along came a band of missionaries, but they were all massacred.',\n",
       " 'as of january 27, 2006, brokeback mountain had grossed over $46 million in north america and more than $10 million in the united states.',\n",
       " 'during the horseplay, hamlin fell and severely injured his hand.',\n",
       " 'one elderly jewish man, the wheelchair bound leon klinghoffer, was killed by the hijackers and thrown overboard.',\n",
       " 'punjab university library has two-storey building and total area of the building is 102,000 sq.',\n",
       " 'it claims to organize several thousands of scientific conferences a year, using names that are similar to or the same as real conferences organized by established scientific groups.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = generate_text(examples)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f751c9-79e0-4a6f-80ab-a1c83cbd6dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in april 2009 a brazilian human rights group, torture never again, awarded the five its chico mendes medal, under the pretext that their rights had been violated.',\n",
       " 'the 51 day standoff and ensuing deaths of 76 men, women, and children--the branch davidians--in waco, texas.',\n",
       " 'mark oaten (born 8 march 1964, watford) is a liberal democrat politician in the united kingdom, and member of parliament for the winchester constituency.',\n",
       " 'another period of colonisation in ancient times was from the romans.',\n",
       " 'photo sequence of 2005 chicagoland crash with ryan briscoe.',\n",
       " 'jesus of nazareth is possibly mentioned in two passages of the work the antiquities of the jews by the jewish historian josephus, written in the late first century ad.',\n",
       " 'israeli efforts to reduce gazan civilian casualties',\n",
       " 'his 45-year career was longer than that of any other studio head.',\n",
       " 'they see the calling of such councils, for example, by a roman emperor lacking the divine authority as groundless and assert that the emperors used the councils to exercise their influence to shape and institute christianity to their liking.',\n",
       " 'in the earliest models (earlier than a macintosh ii), all it did was crash silently, without playing any music.',\n",
       " 'elagabulus engaged in frequent homosexual activities , such as prostituting himself in drag and marrying an enslaved chariot driver.',\n",
       " 'stone soup is an old folk story in which hungry strangers compell the local people of a town into sharing their food.',\n",
       " 'file:donna york.jpg|a barge hauls coal in the louisville and portland canal, the only artificial portion of the ohio river.',\n",
       " 'carwood lipton has appeared on two separate television shows, providing his own commentary in the hbo miniseries band of brothers and the inspirational true story of easy company, we stand alone together: the men of easy company.',\n",
       " 'along came a band of missionaries, but they were all massacred.',\n",
       " 'as of january 27, 2006, brokeback mountain had grossed over $46 million in north america and more than $10 million elsewhere .',\n",
       " 'during the horseplay, hamlin fell and severely injured his hand.',\n",
       " 'one elderly jewish man, the wheelchair -using leon klinghoffer, was murdered by the hijackers and thrown overboard.',\n",
       " 'punjab university library has two-storey building and total area of the building is 102,000 sq.',\n",
       " 'it claims to organize several thousands of scientific conferences a year, using names that are similar to or the same as real conferences organized by established scientific groups.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = examples[\"target_text\"]\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6baee9-2466-4911-b703-9b2375bc919d",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "662e365b-71a2-4067-9b69-8fa0602f2520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4d1f3d69-24b8-4182-956e-3583205c1086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    # # rougeLSum expects newline after each sentence\n",
    "    # preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    # labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "99af2812-4978-4919-9a23-ffab82df34f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, labels = postprocess_text(preds, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5704c327-0df1-48e3-b64a-e26e511512e1",
   "metadata": {},
   "source": [
    "#### ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "df9d78ea-5abf-45cd-9ef2-50ab86e29378",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1de07753-3f95-4bea-8d0f-3b3e5f041d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.9523809523809523, recall=0.9, fmeasure=0.9473684210526316), mid=Score(precision=0.9761904761904762, recall=0.9261904761904762, fmeasure=0.949874686716792), high=Score(precision=1.0, recall=0.9523809523809523, fmeasure=0.9523809523809523)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.875, recall=0.7777777777777778, fmeasure=0.823529411764706), mid=Score(precision=0.9125, recall=0.8638888888888889, fmeasure=0.886764705882353), high=Score(precision=0.95, recall=0.95, fmeasure=0.9500000000000001)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.9523809523809523, recall=0.9, fmeasure=0.9473684210526316), mid=Score(precision=0.9761904761904762, recall=0.9261904761904762, fmeasure=0.949874686716792), high=Score(precision=1.0, recall=0.9523809523809523, fmeasure=0.9523809523809523)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.9523809523809523, recall=0.9, fmeasure=0.9473684210526316), mid=Score(precision=0.9761904761904762, recall=0.9261904761904762, fmeasure=0.949874686716792), high=Score(precision=1.0, recall=0.9523809523809523, fmeasure=0.9523809523809523))}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = metric.compute(predictions=preds, references=labels, use_stemmer=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "27fb4707-3c5f-4896-9420-0299e2195716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 94.9874686716792,\n",
       " 'rouge2': 88.6764705882353,\n",
       " 'rougeL': 94.9874686716792,\n",
       " 'rougeLsum': 94.9874686716792}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key: value.mid.fmeasure * 100 for key, value in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e21f32-1b77-4fa5-a38d-cdcdc9afb807",
   "metadata": {},
   "source": [
    "#### BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1436d8f1-dded-4952-8e09-cbeaa8ddafe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in april 2009 a brazilian human rights group, torture never again, awarded the five its chico mendes medal, because their rights had been violated.',\n",
       " 'the 51 day standoff and ensuing murder of 76 men, women, and children--the branch davidians--in waco, texas.',\n",
       " 'mark oaten (born 8 march 1964, watford) is a liberal democrat politician in the united kingdom, and member of parliament for the winchester constituency.',\n",
       " 'another period of colonisation in ancient times was from the romans.',\n",
       " 'photo sequence of 2005 chicagoland crash with ryan briscoe.',\n",
       " 'jesus of nazareth is probably mentioned in two passages of the work the antiquities of the jews by the jewish historian josephus, written in the late first century ad.',\n",
       " 'israeli attempts to reduce gazan civilian casualties',\n",
       " 'his 45-year career exceeded that of any other studio head.',\n",
       " 'they see the calling of such councils, for example, by a roman emperor lacking the divine authority as preposterous and assert that the emperors used the councils to exercise their influence to shape and institute christianity to their liking.',\n",
       " 'in the earliest models (earlier than a macintosh ii), all it did was crash silently, without playing any fancy music.',\n",
       " 'elagabulus engaged in frequent homosexual perversions, such as prostituting himself in drag and marrying an enslaved chariot driver.',\n",
       " 'stone soup is an old folk story in which hungry strangers trick the local people of a town into sharing their food.',\n",
       " 'file:donna york.jpg|a barge hauls coal in the louisville and portland canal, the only man-made portion of the ohio river.',\n",
       " 'carwood lipton has appeared on two separate television shows, providing his own commentary in the popular hbo miniseries band of brothers and the inspirational true story of easy company, we stand alone together: the men of simple company.',\n",
       " 'along came a band of missionaries, but they were all massacred.',\n",
       " 'as of january 27, 2006, brokeback mountain had grossed over $46 million in north america and more than $10 million overseas.',\n",
       " 'during the horseplay, hamlin fell and severely injured his hand.',\n",
       " 'one elderly jewish man, the wheelchair bound leon klinghoffer, was murdered by the hijackers and thrown overboard.',\n",
       " 'punjab university library has two-storey building and total area of the building is 102,000 sq.',\n",
       " 'it claims to organize several thousands of scientific conferences a year, using names that are similar to or even the same as real conferences organized by established scientific groups.']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4a5ad595-2535-4559-8921-9478ca3a286d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['in april 2009 a brazilian human rights group, torture never again, awarded the five its chico mendes medal, under the pretext that their rights had been violated.'],\n",
       " ['the 51 day standoff and ensuing deaths of 76 men, women, and children--the branch davidians--in waco, texas.'],\n",
       " ['mark oaten (born 8 march 1964, watford) is a liberal democrat politician in the united kingdom, and member of parliament for the winchester constituency.'],\n",
       " ['another period of colonisation in ancient times was from the romans.'],\n",
       " ['photo sequence of 2005 chicagoland crash with ryan briscoe.'],\n",
       " ['jesus of nazareth is possibly mentioned in two passages of the work the antiquities of the jews by the jewish historian josephus, written in the late first century ad.'],\n",
       " ['israeli efforts to reduce gazan civilian casualties'],\n",
       " ['his 45-year career was longer than that of any other studio head.'],\n",
       " ['they see the calling of such councils, for example, by a roman emperor lacking the divine authority as groundless and assert that the emperors used the councils to exercise their influence to shape and institute christianity to their liking.'],\n",
       " ['in the earliest models (earlier than a macintosh ii), all it did was crash silently, without playing any music.'],\n",
       " ['elagabulus engaged in frequent homosexual activities , such as prostituting himself in drag and marrying an enslaved chariot driver.'],\n",
       " ['stone soup is an old folk story in which hungry strangers compell the local people of a town into sharing their food.'],\n",
       " ['file:donna york.jpg|a barge hauls coal in the louisville and portland canal, the only artificial portion of the ohio river.'],\n",
       " ['carwood lipton has appeared on two separate television shows, providing his own commentary in the hbo miniseries band of brothers and the inspirational true story of easy company, we stand alone together: the men of easy company.'],\n",
       " ['along came a band of missionaries, but they were all massacred.'],\n",
       " ['as of january 27, 2006, brokeback mountain had grossed over $46 million in north america and more than $10 million elsewhere .'],\n",
       " ['during the horseplay, hamlin fell and severely injured his hand.'],\n",
       " ['one elderly jewish man, the wheelchair -using leon klinghoffer, was murdered by the hijackers and thrown overboard.'],\n",
       " ['punjab university library has two-storey building and total area of the building is 102,000 sq.'],\n",
       " ['it claims to organize several thousands of scientific conferences a year, using names that are similar to or the same as real conferences organized by established scientific groups.']]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1b26bec5-f1f6-4305-82ce-88beff8ccb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [\"I am the same.\", \"oh yea nope\"]\n",
    "labels = [[\"I am the same.\"], [\"oh yea nopee\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13c12a-ae1b-4581-a2a6-577e78aa6914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5121b797-cd6c-4343-a114-ea751546ad63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([(x == y[0]) for x, y in zip(preds, labels)]) / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "78a0c179-3fd7-41ec-8979-e89c85b2c50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('in april 2009 a brazilian human rights group, torture never again, awarded the five its chico mendes medal, because their rights had been violated.',\n",
       " ['in april 2009 a brazilian human rights group, torture never again, awarded the five its chico mendes medal, under the pretext that their rights had been violated.'])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(preds, labels))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "28acfe4d-cc5f-48b2-bdb1-cdc6f9285ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bab26c4a-a861-43f8-a074-e18f20366d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['as of january 27, 2006, brokeback mountain had grossed over $46 million in north america and more than $10 million overseas.',\n",
       " 'during the horseplay, hamlin fell and injured his hand.']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d07aa-6603-4832-a5eb-45d6a1f70a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c185c4ec-78ed-4aed-bec9-82d7faa6ddef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c3b4e2e7-8d5c-4463-af84-d471b3da8d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric2 = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e9f32bd1-41f8-459f-b01e-74fe6190d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = metric2.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8410aab4-254d-4f39-a2b8-62844f5f162d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 87.5854401903611,\n",
       " 'counts': [36, 32, 29, 26],\n",
       " 'totals': [37, 35, 33, 31],\n",
       " 'precisions': [97.29729729729729,\n",
       "  91.42857142857143,\n",
       "  87.87878787878788,\n",
       "  83.87096774193549],\n",
       " 'bp': 0.9733349348192527,\n",
       " 'sys_len': 37,\n",
       " 'ref_len': 38}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88602aa1-d5df-4c87-9598-ef9fa7762f62",
   "metadata": {},
   "source": [
    "### Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f908be4e-5388-4967-9fb1-6528d4dc4123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in april 2009 a brazilian human rights group, torture never again, awarded the five its chico mendes medal, because their rights had been violated.',\n",
       " 'the 51 day standoff and ensuing murder of 76 men, women, and children--the branch davidians--in waco, texas.',\n",
       " 'mark oaten (born 8 march 1964, watford) is a disgraced liberal democrat politician in the united kingdom, and member of parliament for the winchester constituency.',\n",
       " 'another infamous period of colonisation in ancient times was from the romans.',\n",
       " 'photo sequence of astonishing 2005 chicagoland crash with ryan briscoe.',\n",
       " 'jesus of nazareth is probably mentioned in two passages of the work the antiquities of the jews by the jewish historian josephus, written in the late first century ad.',\n",
       " 'israeli attempts to reduce gazan civilian casualties',\n",
       " 'his 45-year career exceeded that of any other studio head.',\n",
       " 'they see the calling of such councils, for example, by a roman emperor lacking the divine authority as preposterous and assert that the emperors used the councils to exercise their influence to shape and institute christianity to their liking.',\n",
       " 'in the earliest models (earlier than a macintosh ii), all it did was crash silently, without playing any fancy music.',\n",
       " 'elagabulus engaged in frequent homosexual perversions , such as prostituting himself in drag and marrying an enslaved chariot driver.',\n",
       " 'stone soup is an old folk story in which hungry strangers trick the local people of a town into sharing their food.',\n",
       " 'file:donna york.jpg|a barge hauls coal in the louisville and portland canal, the only man-made portion of the ohio river.',\n",
       " 'carwood lipton has appeared on two separate television shows, providing his own commentary in the popular hbo miniseries band of brothers and the inspirational true story of easy company, we stand alone together: the men of easy company.',\n",
       " 'along came a band of missionaries, but they were all horribly massacred.',\n",
       " 'as of january 27, 2006, brokeback mountain had grossed over $46 million in north america and more than $10 million overseas .',\n",
       " 'during the unnecessary horseplay, hamlin fell and severely injured his hand.',\n",
       " 'one elderly jewish man, the wheelchair bound leon klinghoffer, was murdered by the hijackers and thrown overboard.',\n",
       " 'punjab university library has beautiful two-storey building and total area of the building is 102,000 sq.',\n",
       " 'it claims to organize several thousands of scientific conferences a year, using names that are similar to or even the same as real conferences organized by established scientific groups.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[\"source_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1de00a5-953f-48db-82e4-56bc3b2c1de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['rev_id', 'source_text', 'target_text'],\n",
       "        num_rows: 967\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['rev_id', 'source_text', 'target_text'],\n",
       "        num_rows: 52093\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['rev_id', 'source_text', 'target_text'],\n",
       "        num_rows: 671\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnc_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da37e47f-de1f-4e12-9b9c-da59a304914d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE: in april 2009 a brazilian human rights group, torture never again, awarded the five its chico mendes medal, because their rights had been violated. \n",
      "\n",
      "TARGET: in april 2009 a brazilian human rights group, torture never again, awarded the five its chico mendes medal, under the pretext that their rights had been violated. \n",
      "\n",
      "PREDIC: in april 2009 a brazilian human rights group, torture never again, awarded the five its chico mendes medal, claiming that their rights had been violated. \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: the 51 day standoff and ensuing murder of 76 men, women, and children--the branch davidians--in waco, texas. \n",
      "\n",
      "TARGET: the 51 day standoff and ensuing deaths of 76 men, women, and children--the branch davidians--in waco, texas. \n",
      "\n",
      "PREDIC: the 51 day standoff and ensuing killing of 76 men, women, and children--the branch davidians--in waco, texas. \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: mark oaten (born 8 march 1964, watford) is a disgraced liberal democrat politician in the united kingdom, and member of parliament for the winchester constituency. \n",
      "\n",
      "TARGET: mark oaten (born 8 march 1964, watford) is a liberal democrat politician in the united kingdom, and member of parliament for the winchester constituency. \n",
      "\n",
      "PREDIC: mark oaten (born 8 march 1964, watford) is a liberal democrat politician in the united kingdom, and member of parliament for the winchester constituency. \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: another infamous period of colonisation in ancient times was from the romans. \n",
      "\n",
      "TARGET: another period of colonisation in ancient times was from the romans. \n",
      "\n",
      "PREDIC: another period of colonisation in ancient times was from the romans. \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: photo sequence of astonishing 2005 chicagoland crash with ryan briscoe. \n",
      "\n",
      "TARGET: photo sequence of 2005 chicagoland crash with ryan briscoe. \n",
      "\n",
      "PREDIC: photo sequence of 2005 chicagoland crash with ryan briscoe. \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: jesus of nazareth is probably mentioned in two passages of the work the antiquities of the jews by the jewish historian josephus, written in the late first century ad. \n",
      "\n",
      "TARGET: jesus of nazareth is possibly mentioned in two passages of the work the antiquities of the jews by the jewish historian josephus, written in the late first century ad. \n",
      "\n",
      "PREDIC: jesus of nazareth is mentioned in two passages of the work the antiquities of the jews by the jewish historian josephus, written in the late first century ad. \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: israeli attempts to reduce gazan civilian casualties \n",
      "\n",
      "TARGET: israeli efforts to reduce gazan civilian casualties \n",
      "\n",
      "PREDIC: israeli aims to reduce gazan civilian casualties \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: his 45-year career exceeded that of any other studio head. \n",
      "\n",
      "TARGET: his 45-year career was longer than that of any other studio head. \n",
      "\n",
      "PREDIC: his 45-year career exceeded that of any other studio head. \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: they see the calling of such councils, for example, by a roman emperor lacking the divine authority as preposterous and assert that the emperors used the councils to exercise their influence to shape and institute christianity to their liking. \n",
      "\n",
      "TARGET: they see the calling of such councils, for example, by a roman emperor lacking the divine authority as groundless and assert that the emperors used the councils to exercise their influence to shape and institute christianity to their liking. \n",
      "\n",
      "PREDIC: they see the calling of such councils, for example, by a roman emperor lacking the divine authority as preposterous and assert that the emperors used the councils to exercise their influence to shape and institute christianity to their liking. \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: in the earliest models (earlier than a macintosh ii), all it did was crash silently, without playing any fancy music. \n",
      "\n",
      "TARGET: in the earliest models (earlier than a macintosh ii), all it did was crash silently, without playing any music. \n",
      "\n",
      "PREDIC: in the earliest models (earlier than a macintosh ii), all it did was crash silently, without playing any music. \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: elagabulus engaged in frequent homosexual perversions , such as prostituting himself in drag and marrying an enslaved chariot driver. \n",
      "\n",
      "TARGET: elagabulus engaged in frequent homosexual activities , such as prostituting himself in drag and marrying an enslaved chariot driver. \n",
      "\n",
      "PREDIC: elagabulus engaged in frequent homosexual activities, such as prostituting himself in drag and marrying an enslaved chariot driver. \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: stone soup is an old folk story in which hungry strangers trick the local people of a town into sharing their food. \n",
      "\n",
      "TARGET: stone soup is an old folk story in which hungry strangers compell the local people of a town into sharing their food. \n",
      "\n",
      "PREDIC: stone soup is an old folk story in which hungry strangers trick the local people of a town into sharing their food. \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: file:donna york.jpg|a barge hauls coal in the louisville and portland canal, the only man-made portion of the ohio river. \n",
      "\n",
      "TARGET: file:donna york.jpg|a barge hauls coal in the louisville and portland canal, the only artificial portion of the ohio river. \n",
      "\n",
      "PREDIC: file:donna york.jpg|a barge hauls coal in the louisville and portland canal, the only artificial portion of the ohio river. \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: carwood lipton has appeared on two separate television shows, providing his own commentary in the popular hbo miniseries band of brothers and the inspirational true story of easy company, we stand alone together: the men of easy company. \n",
      "\n",
      "TARGET: carwood lipton has appeared on two separate television shows, providing his own commentary in the hbo miniseries band of brothers and the inspirational true story of easy company, we stand alone together: the men of easy company. \n",
      "\n",
      "PREDIC: carwood lipton has appeared on two separate television shows, providing his own commentary in the hbo miniseries band of brothers and the inspirational true story of easy company, we stand alone together: the men of easy country. \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: along came a band of missionaries, but they were all horribly massacred. \n",
      "\n",
      "TARGET: along came a band of missionaries, but they were all massacred. \n",
      "\n",
      "PREDIC: along came a band of missionaries, but they were all massacred. \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: as of january 27, 2006, brokeback mountain had grossed over $46 million in north america and more than $10 million overseas . \n",
      "\n",
      "TARGET: as of january 27, 2006, brokeback mountain had grossed over $46 million in north america and more than $10 million elsewhere . \n",
      "\n",
      "PREDIC: as of january 27, 2006, brokeback mountain had grossed over $46 million in north america and more than $10 million in the united states. \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: during the unnecessary horseplay, hamlin fell and severely injured his hand. \n",
      "\n",
      "TARGET: during the horseplay, hamlin fell and severely injured his hand. \n",
      "\n",
      "PREDIC: during the horseplay, hamlin fell and severely injured his hand. \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: one elderly jewish man, the wheelchair bound leon klinghoffer, was murdered by the hijackers and thrown overboard. \n",
      "\n",
      "TARGET: one elderly jewish man, the wheelchair -using leon klinghoffer, was murdered by the hijackers and thrown overboard. \n",
      "\n",
      "PREDIC: one elderly jewish man, the wheelchair bound leon klinghoffer, was killed by the hijackers and thrown overboard. \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: punjab university library has beautiful two-storey building and total area of the building is 102,000 sq. \n",
      "\n",
      "TARGET: punjab university library has two-storey building and total area of the building is 102,000 sq. \n",
      "\n",
      "PREDIC: punjab university library has two-storey building and total area of the building is 102,000 sq. \n",
      "\n",
      "-----------------------------------------------------------\n",
      "SOURCE: it claims to organize several thousands of scientific conferences a year, using names that are similar to or even the same as real conferences organized by established scientific groups. \n",
      "\n",
      "TARGET: it claims to organize several thousands of scientific conferences a year, using names that are similar to or the same as real conferences organized by established scientific groups. \n",
      "\n",
      "PREDIC: it claims to organize several thousands of scientific conferences a year, using names that are similar to or the same as real conferences organized by established scientific groups. \n",
      "\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for source, target, pred in zip(examples[\"source_text\"], labels, preds):\n",
    "    print(f\"SOURCE: {source} \\n\")\n",
    "    print(f\"TARGET: {target} \\n\")\n",
    "    print(f\"PREDIC: {pred} \\n\")\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4617fcd2-eb3f-44f7-8d97-794e1c3d50ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af744507-ee99-4b44-98a3-db3f54390b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce19b189-c1ea-472a-bdf4-c2dc2712e091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57ff2f-f88f-461c-a19a-b92e3cfb6759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c3fc290-03ba-44e1-b398-781f239bc7e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inference Walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8a14de02-007f-4276-99d7-96be2278c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = [\n",
    "    \"adequate testing for adverse health effects as well as performance data for these devices are seriously lacking.\",\n",
    "    \"I am a really great human being\",\n",
    "]\n",
    "\n",
    "# inputs = tokenizer.encode(\n",
    "#     sample_text, return_tensors=\"pt\", max_length=max_source_length, truncation=True\n",
    "# )\n",
    "\n",
    "inputs = tokenizer(sample_text, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8ea30806-02b4-4f14-b21e-c699f19c0afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 37462,   877,  3044,    13, 12661,   474,  3038,    25,   157,\n",
       "            25,   819,   414,    13,   209,  2110,    32,  3640, 12622,     4,\n",
       "             2],\n",
       "        [    0,   100,   524,    10,   269,   372,  1050,   145,     2,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ff28c2a3-0971-49fe-a8b3-a2fbe0cc70eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_length=max_target_length,\n",
    "    min_length=4,\n",
    "    length_penalty=2,\n",
    "    num_beams=4,\n",
    "    early_stopping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f6141573-688f-44fd-8f40-57776276c3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,     0, 37462,   877,  3044,    13, 12661,   474,  3038,    25,\n",
       "           157,    25,   819,   414,    13,   209,  2110,    32, 12622,     4,\n",
       "             2],\n",
       "        [    2,     0,   100,   524,    10,   269,   372,  1050,   145,     2,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "32ec0e3e-a440-4ffb-8f88-8a489519637a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 21])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8e037ee8-d412-4dff-b732-e2c8e7a97a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3b0a9666-acfe-4412-aeb8-5e4c20daac7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adequate testing for adverse health effects as well as performance data for these devices are lacking.',\n",
       " 'I am a really great human being']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fddc45-9ba5-4bf5-bda9-23515e350908",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765dd185-cd27-4e70-a6d0-eff59a7da281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debe9ad1-3a2f-45b7-a043-818a120d473e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b0a65b-0b4b-4b09-a335-3b68567df20e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba3991ba-0f19-4627-a1ae-3ccb1e281b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 37462, 877, 3044, 13, 12661, 474, 3038, 25, 157, 25, 819, 414, 13, 209, 2110, 32, 3640, 12622, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(sample_text)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6dc0326-4ea2-4118-a8c9-41feae45a2ca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 37462,\n",
       " 877,\n",
       " 3044,\n",
       " 13,\n",
       " 12661,\n",
       " 474,\n",
       " 3038,\n",
       " 25,\n",
       " 157,\n",
       " 25,\n",
       " 819,\n",
       " 414,\n",
       " 13,\n",
       " 209,\n",
       " 2110,\n",
       " 32,\n",
       " 3640,\n",
       " 12622,\n",
       " 4,\n",
       " 2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f274466-38d5-471c-b3ca-b137b3b06601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adequ',\n",
       " 'ate',\n",
       " 'testing',\n",
       " 'for',\n",
       " 'adverse',\n",
       " 'health',\n",
       " 'effects',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'performance',\n",
       " 'data',\n",
       " 'for',\n",
       " 'these',\n",
       " 'devices',\n",
       " 'are',\n",
       " 'seriously',\n",
       " 'lacking',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a60b285c-7b56-45ad-845b-d1c4af125135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'adequ',\n",
       " 'ate',\n",
       " 'testing',\n",
       " 'for',\n",
       " 'adverse',\n",
       " 'health',\n",
       " 'effects',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'performance',\n",
       " 'data',\n",
       " 'for',\n",
       " 'these',\n",
       " 'devices',\n",
       " 'are',\n",
       " 'seriously',\n",
       " 'lacking',\n",
       " '.',\n",
       " '</s>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0c71deb-b567-479d-9991-e9f908524fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'adequ',\n",
       " 'ate',\n",
       " 'testing',\n",
       " 'for',\n",
       " 'adverse',\n",
       " 'health',\n",
       " 'effects',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'performance',\n",
       " 'data',\n",
       " 'for',\n",
       " 'these',\n",
       " 'devices',\n",
       " 'are',\n",
       " 'seriously',\n",
       " 'lacking',\n",
       " '.',\n",
       " '</s>']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba20fc52-849e-4837-89e8-36779137bde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='/home/cdsw/models/bart-tst-oneword', vocab_size=50265, model_max_len=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f3928-7c4c-414a-b2a4-e4290857a523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a183ed7-6269-49aa-bf68-382f147c8325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3da305-8dbc-4e02-811f-256213e94ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905668a8-fe29-4321-8a3f-6246f29e80a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ff9f9-eb3d-4a29-8f96-74acf7b6c002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857137ad-6896-4343-8893-88ab4a19e480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea741d-9efb-4083-83fd-4d40662f3d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1381d4-69cd-4b04-b7da-c2414c40d528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eecd80b0-ae16-4c65-82aa-f8dfb0cbc95b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-044b9d4df4f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"another infamous period of colonisation in ancient times was from the romans.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0;31m# all model-specific keyword inputs are removed from `model_kwargs`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0minputs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_model_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbos_token_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0;31m# 3. Define other model kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "model.generate(\"another infamous period of colonisation in ancient times was from the romans.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2278ef-6bdf-4004-81ce-b358c6e86857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729981fd-0245-4bb9-95dd-eefc7e1609ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fae08373-b907-4a6a-b9d0-3620c2518353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rev_id': '101665256',\n",
       " 'source_text': 'another infamous period of colonisation in ancient times was from the romans.',\n",
       " 'target_text': 'another period of colonisation in ancient times was from the romans.'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnc_datasets[\"test\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cacaaf11-f705-4d15-b1a9-055d65871b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"another infamous period of colonisation in ancient times was from the romans.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f2382de-a686-41f5-8b34-b55a75a6f603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 30303, 13358, 675, 9, 17735, 3258, 11, 8178, 498, 21, 31, 5, 14233, 1253, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ecb87a-d17e-4e21-a248-ed21cd036ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5728b1dc-2263-463f-8fb9-b1bb9e6981a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['rev_id', 'source_text', 'target_text'],\n",
       "        num_rows: 967\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['rev_id', 'source_text', 'target_text'],\n",
       "        num_rows: 52093\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['rev_id', 'source_text', 'target_text'],\n",
       "        num_rows: 671\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnc_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c4279-977f-4661-b355-196e36e6131d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20a7e9b0-2716-49c8-b6ad-5581851ef9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla V100-PCIE-32GB'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7495e465-ed6d-4524-accb-9c6acd3d0569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c4d44-9c7d-45c6-b43d-f4c1577975a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/cdsw/models/bart-tst-oneword/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3745e941-4b02-4e84-903a-0b6c21912a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "PORT = os.getenv(\"CDSW_READONLY_PORT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11b5edfd-cfa5-4985-8566-d59f88a244ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8100'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "416ab6ad-64c1-46ad-9329-063424df505d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 2).\n",
       "Contents of stderr:\n",
       "TensorFlow installation not found - running with reduced feature set.\n",
       "usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC]\n",
       "                   [--host ADDR] [--bind_all] [--port PORT]\n",
       "                   [--reuse_port BOOL] [--load_fast {false,auto,true}]\n",
       "                   [--extra_data_server_flags EXTRA_DATA_SERVER_FLAGS]\n",
       "                   [--grpc_creds_type {local,ssl,ssl_dev}]\n",
       "                   [--grpc_data_provider PORT] [--purge_orphaned_data BOOL]\n",
       "                   [--db URI] [--db_import] [--inspect] [--version_tb]\n",
       "                   [--tag TAG] [--event_file PATH] [--path_prefix PATH]\n",
       "                   [--window_title TEXT] [--max_reload_threads COUNT]\n",
       "                   [--reload_interval SECONDS] [--reload_task TYPE]\n",
       "                   [--reload_multifile BOOL]\n",
       "                   [--reload_multifile_inactive_secs SECONDS]\n",
       "                   [--generic_data TYPE]\n",
       "                   [--samples_per_plugin SAMPLES_PER_PLUGIN]\n",
       "                   [--whatif-use-unsafe-custom-prediction YOUR_CUSTOM_PREDICT_FUNCTION.py]\n",
       "                   [--whatif-data-dir PATH]\n",
       "                   {serve,dev} ...\n",
       "tensorboard: error: argument --port: invalid <lambda> value: '$CDSW_READONLY_PORT'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=/home/cdsw/models/bart-tst-oneword/runs --port $CDSW_READONLY_PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8c982d3-f04a-48f2-8904-28a345923dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8100'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"CDSW_READONLY_PORT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2dcee-615a-4085-a034-84e8fe1edeeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6e06e6-16c7-4ba9-b780-836b1bd034ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08517ca5-cf8b-45fb-90bf-8f93d226d82a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03635fb5-992a-4874-99ff-e54ae2de071f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc31c1-7239-476b-bcec-d0788df319f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1792fdf9-660a-43cf-82d5-51320c1ef9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd84758b-cd17-4d61-9746-9f5cd143c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import datasets\n",
    "import nltk  # Here to have a nice missing dependency error message early on\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric, load_from_disk\n",
    "\n",
    "import transformers\n",
    "from filelock import FileLock\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    HfArgumentParser,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.file_utils import is_offline_mode\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fed9bee5-df26-49cc-ab1a-bae3279af913",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mSeq2SeqTrainingArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moverwrite_output_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdo_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdo_eval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdo_predict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mevaluation_strategy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntervalStrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'no'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mper_device_train_batch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mper_device_eval_batch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mper_gpu_train_batch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mper_gpu_eval_batch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0meval_accumulation_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5e-05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mweight_decay\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0madam_beta1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0madam_beta2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0madam_epsilon\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-08\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlr_scheduler_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSchedulerType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwarmup_ratio\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwarmup_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlog_level\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'passive'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlog_level_replica\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'passive'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlog_on_each_node\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogging_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogging_strategy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntervalStrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogging_first_step\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogging_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msave_strategy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntervalStrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msave_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msave_total_limit\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msave_on_each_node\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mno_cuda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbf16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfp16_opt_level\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'O1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhalf_precision_backend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbf16_full_eval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfp16_full_eval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtf32\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlocal_rank\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mxpu_backend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtpu_num_cores\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtpu_metrics_debug\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdataloader_drop_last\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0meval_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdataloader_num_workers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpast_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrun_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mremove_unused_columns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabel_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mload_best_model_at_end\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetric_for_best_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgreater_is_better\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mignore_data_skip\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msharded_ddp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdeepspeed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabel_smoothing_factor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moptim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizerNames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adamw_hf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0madafactor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgroup_by_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlength_column_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'length'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreport_to\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mddp_find_unused_parameters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mddp_bucket_cap_mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdataloader_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskip_memory_metrics\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_legacy_prediction_loop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpush_to_hub\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhub_model_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhub_strategy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHubStrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'every_save'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhub_token\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgradient_checkpointing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfp16_backend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpush_to_hub_model_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpush_to_hub_organization\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpush_to_hub_token\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmp_parameters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msortish_sampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpredict_with_generate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgeneration_max_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgeneration_num_beams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "TrainingArguments is the subset of the arguments we use in our example scripts **which relate to the training loop\n",
       "itself**.\n",
       "\n",
       "Using [`HfArgumentParser`] we can turn this class into\n",
       "[argparse](https://docs.python.org/3/library/argparse#module-argparse) arguments that can be specified on the\n",
       "command line.\n",
       "\n",
       "Parameters:\n",
       "    output_dir (`str`):\n",
       "        The output directory where the model predictions and checkpoints will be written.\n",
       "    overwrite_output_dir (`bool`, *optional*, defaults to `False`):\n",
       "        If `True`, overwrite the content of the output directory. Use this to continue training if `output_dir`\n",
       "        points to a checkpoint directory.\n",
       "    do_train (`bool`, *optional*, defaults to `False`):\n",
       "        Whether to run training or not. This argument is not directly used by [`Trainer`], it's intended to be used\n",
       "        by your training/evaluation scripts instead. See the [example\n",
       "        scripts](https://github.com/huggingface/transformers/tree/master/examples) for more details.\n",
       "    do_eval (`bool`, *optional*):\n",
       "        Whether to run evaluation on the validation set or not. Will be set to `True` if `evaluation_strategy` is\n",
       "        different from `\"no\"`. This argument is not directly used by [`Trainer`], it's intended to be used by your\n",
       "        training/evaluation scripts instead. See the [example\n",
       "        scripts](https://github.com/huggingface/transformers/tree/master/examples) for more details.\n",
       "    do_predict (`bool`, *optional*, defaults to `False`):\n",
       "        Whether to run predictions on the test set or not. This argument is not directly used by [`Trainer`], it's\n",
       "        intended to be used by your training/evaluation scripts instead. See the [example\n",
       "        scripts](https://github.com/huggingface/transformers/tree/master/examples) for more details.\n",
       "    evaluation_strategy (`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `\"no\"`):\n",
       "        The evaluation strategy to adopt during training. Possible values are:\n",
       "\n",
       "            - `\"no\"`: No evaluation is done during training.\n",
       "            - `\"steps\"`: Evaluation is done (and logged) every `eval_steps`.\n",
       "            - `\"epoch\"`: Evaluation is done at the end of each epoch.\n",
       "\n",
       "    prediction_loss_only (`bool`, *optional*, defaults to `False`):\n",
       "        When performing evaluation and generating predictions, only returns the loss.\n",
       "    per_device_train_batch_size (`int`, *optional*, defaults to 8):\n",
       "        The batch size per GPU/TPU core/CPU for training.\n",
       "    per_device_eval_batch_size (`int`, *optional*, defaults to 8):\n",
       "        The batch size per GPU/TPU core/CPU for evaluation.\n",
       "    gradient_accumulation_steps (`int`, *optional*, defaults to 1):\n",
       "        Number of updates steps to accumulate the gradients for, before performing a backward/update pass.\n",
       "\n",
       "        <Tip warning={true}>\n",
       "\n",
       "        When using gradient accumulation, one step is counted as one step with backward pass. Therefore, logging,\n",
       "        evaluation, save will be conducted every `gradient_accumulation_steps * xxx_step` training examples.\n",
       "\n",
       "        </Tip>\n",
       "\n",
       "    eval_accumulation_steps (`int`, *optional*):\n",
       "        Number of predictions steps to accumulate the output tensors for, before moving the results to the CPU. If\n",
       "        left unset, the whole predictions are accumulated on GPU/TPU before being moved to the CPU (faster but\n",
       "        requires more memory).\n",
       "    learning_rate (`float`, *optional*, defaults to 5e-5):\n",
       "        The initial learning rate for [`AdamW`] optimizer.\n",
       "    weight_decay (`float`, *optional*, defaults to 0):\n",
       "        The weight decay to apply (if not zero) to all layers except all bias and LayerNorm weights in [`AdamW`]\n",
       "        optimizer.\n",
       "    adam_beta1 (`float`, *optional*, defaults to 0.9):\n",
       "        The beta1 hyperparameter for the [`AdamW`] optimizer.\n",
       "    adam_beta2 (`float`, *optional*, defaults to 0.999):\n",
       "        The beta2 hyperparameter for the [`AdamW`] optimizer.\n",
       "    adam_epsilon (`float`, *optional*, defaults to 1e-8):\n",
       "        The epsilon hyperparameter for the [`AdamW`] optimizer.\n",
       "    max_grad_norm (`float`, *optional*, defaults to 1.0):\n",
       "        Maximum gradient norm (for gradient clipping).\n",
       "    num_train_epochs(`float`, *optional*, defaults to 3.0):\n",
       "        Total number of training epochs to perform (if not an integer, will perform the decimal part percents of\n",
       "        the last epoch before stopping training).\n",
       "    max_steps (`int`, *optional*, defaults to -1):\n",
       "        If set to a positive number, the total number of training steps to perform. Overrides `num_train_epochs`.\n",
       "        In case of using a finite iterable dataset the training may stop before reaching the set number of steps\n",
       "        when all data is exhausted\n",
       "    lr_scheduler_type (`str` or [`SchedulerType`], *optional*, defaults to `\"linear\"`):\n",
       "        The scheduler type to use. See the documentation of [`SchedulerType`] for all possible values.\n",
       "    warmup_ratio (`float`, *optional*, defaults to 0.0):\n",
       "        Ratio of total training steps used for a linear warmup from 0 to `learning_rate`.\n",
       "    warmup_steps (`int`, *optional*, defaults to 0):\n",
       "        Number of steps used for a linear warmup from 0 to `learning_rate`. Overrides any effect of `warmup_ratio`.\n",
       "    log_level (`str`, *optional*, defaults to `passive`):\n",
       "        Logger log level to use on the main process. Possible choices are the log levels as strings: 'debug',\n",
       "        'info', 'warning', 'error' and 'critical', plus a 'passive' level which doesn't set anything and lets the\n",
       "        application set the level.\n",
       "    log_level_replica (`str`, *optional*, defaults to `passive`):\n",
       "        Logger log level to use on replicas. Same choices as `log_level`\"\n",
       "    log_on_each_node (`bool`, *optional*, defaults to `True`):\n",
       "        In multinode distributed training, whether to log using `log_level` once per node, or only on the main\n",
       "        node.\n",
       "    logging_dir (`str`, *optional*):\n",
       "        [TensorBoard](https://www.tensorflow.org/tensorboard) log directory. Will default to\n",
       "        *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***.\n",
       "    logging_strategy (`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `\"steps\"`):\n",
       "        The logging strategy to adopt during training. Possible values are:\n",
       "\n",
       "            - `\"no\"`: No logging is done during training.\n",
       "            - `\"epoch\"`: Logging is done at the end of each epoch.\n",
       "            - `\"steps\"`: Logging is done every `logging_steps`.\n",
       "\n",
       "    logging_first_step (`bool`, *optional*, defaults to `False`):\n",
       "        Whether to log and evaluate the first `global_step` or not.\n",
       "    logging_steps (`int`, *optional*, defaults to 500):\n",
       "        Number of update steps between two logs if `logging_strategy=\"steps\"`.\n",
       "    logging_nan_inf_filter (`bool`, *optional*, defaults to `True`):\n",
       "        Whether to filter `nan` and `inf` losses for logging. If set to `True` the loss of every step that is `nan`\n",
       "        or `inf` is filtered and the average loss of the current logging window is taken instead.\n",
       "\n",
       "        <Tip>\n",
       "\n",
       "        `logging_nan_inf_filter` only influences the logging of loss values, it does not change the behavior the\n",
       "        gradient is computed or applied to the model.\n",
       "\n",
       "        </Tip>\n",
       "\n",
       "    save_strategy (`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `\"steps\"`):\n",
       "        The checkpoint save strategy to adopt during training. Possible values are:\n",
       "\n",
       "            - `\"no\"`: No save is done during training.\n",
       "            - `\"epoch\"`: Save is done at the end of each epoch.\n",
       "            - `\"steps\"`: Save is done every `save_steps`.\n",
       "    save_steps (`int`, *optional*, defaults to 500):\n",
       "        Number of updates steps before two checkpoint saves if `save_strategy=\"steps\"`.\n",
       "    save_total_limit (`int`, *optional*):\n",
       "        If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in\n",
       "        `output_dir`.\n",
       "    save_on_each_node (`bool`, *optional*, defaults to `False`):\n",
       "        When doing multi-node distributed training, whether to save models and checkpoints on each node, or only on\n",
       "        the main one.\n",
       "\n",
       "        This should not be activated when the different nodes use the same storage as the files will be saved with\n",
       "        the same names for each node.\n",
       "    no_cuda (`bool`, *optional*, defaults to `False`):\n",
       "        Whether to not use CUDA even when it is available or not.\n",
       "    seed (`int`, *optional*, defaults to 42):\n",
       "        Random seed that will be set at the beginning of training. To ensure reproducibility across runs, use the\n",
       "        [`~Trainer.model_init`] function to instantiate the model if it has some randomly initialized parameters.\n",
       "    bf16 (`bool`, *optional*, defaults to `False`):\n",
       "        Whether to use bf16 16-bit (mixed) precision training instead of 32-bit training. Requires Ampere or higher\n",
       "        NVIDIA architecture. This is an experimental API and it may change.\n",
       "    fp16 (`bool`, *optional*, defaults to `False`):\n",
       "        Whether to use fp16 16-bit (mixed) precision training instead of 32-bit training.\n",
       "    fp16_opt_level (`str`, *optional*, defaults to 'O1'):\n",
       "        For `fp16` training, Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3']. See details on\n",
       "        the [Apex documentation](https://nvidia.github.io/apex/amp).\n",
       "    fp16_backend (`str`, *optional*, defaults to `\"auto\"`):\n",
       "        This argument is deprecated. Use `half_precision_backend` instead.\n",
       "    half_precision_backend (`str`, *optional*, defaults to `\"auto\"`):\n",
       "        The backend to use for mixed precision training. Must be one of `\"auto\"`, `\"amp\"` or `\"apex\"`. `\"auto\"`\n",
       "        will use AMP or APEX depending on the PyTorch version detected, while the other choices will force the\n",
       "        requested backend.\n",
       "    bf16_full_eval (`bool`, *optional*, defaults to `False`):\n",
       "        Whether to use full bfloat16 evaluation instead of 32-bit. This will be faster and save memory but can harm\n",
       "        metric values. This is an experimental API and it may change.\n",
       "    fp16_full_eval (`bool`, *optional*, defaults to `False`):\n",
       "        Whether to use full float16 evaluation instead of 32-bit. This will be faster and save memory but can harm\n",
       "        metric values.\n",
       "    tf32 (`bool`, *optional*):\n",
       "        Whether to enable tf32 mode, available in Ampere and newer GPU architectures. This is an experimental API\n",
       "        and it may change.\n",
       "    local_rank (`int`, *optional*, defaults to -1):\n",
       "        Rank of the process during distributed training.\n",
       "    xpu_backend (`str`, *optional*):\n",
       "        The backend to use for xpu distributed training. Must be one of `\"mpi\"` or `\"ccl\"`.\n",
       "    tpu_num_cores (`int`, *optional*):\n",
       "        When training on TPU, the number of TPU cores (automatically passed by launcher script).\n",
       "    dataloader_drop_last (`bool`, *optional*, defaults to `False`):\n",
       "        Whether to drop the last incomplete batch (if the length of the dataset is not divisible by the batch size)\n",
       "        or not.\n",
       "    eval_steps (`int`, *optional*):\n",
       "        Number of update steps between two evaluations if `evaluation_strategy=\"steps\"`. Will default to the same\n",
       "        value as `logging_steps` if not set.\n",
       "    dataloader_num_workers (`int`, *optional*, defaults to 0):\n",
       "        Number of subprocesses to use for data loading (PyTorch only). 0 means that the data will be loaded in the\n",
       "        main process.\n",
       "    past_index (`int`, *optional*, defaults to -1):\n",
       "        Some models like [TransformerXL](../model_doc/transformerxl) or [XLNet](../model_doc/xlnet) can make use of\n",
       "        the past hidden states for their predictions. If this argument is set to a positive int, the `Trainer` will\n",
       "        use the corresponding output (usually index 2) as the past state and feed it to the model at the next\n",
       "        training step under the keyword argument `mems`.\n",
       "    run_name (`str`, *optional*):\n",
       "        A descriptor for the run. Typically used for [wandb](https://www.wandb.com/) and\n",
       "        [mlflow](https://www.mlflow.org/) logging.\n",
       "    disable_tqdm (`bool`, *optional*):\n",
       "        Whether or not to disable the tqdm progress bars and table of metrics produced by\n",
       "        [`~notebook.NotebookTrainingTracker`] in Jupyter Notebooks. Will default to `True` if the logging level is\n",
       "        set to warn or lower (default), `False` otherwise.\n",
       "    remove_unused_columns (`bool`, *optional*, defaults to `True`):\n",
       "        If using `datasets.Dataset` datasets, whether or not to automatically remove the columns unused by the\n",
       "        model forward method.\n",
       "\n",
       "        (Note that this behavior is not implemented for [`TFTrainer`] yet.)\n",
       "    label_names (`List[str]`, *optional*):\n",
       "        The list of keys in your dictionary of inputs that correspond to the labels.\n",
       "\n",
       "        Will eventually default to `[\"labels\"]` except if the model used is one of the `XxxForQuestionAnswering` in\n",
       "        which case it will default to `[\"start_positions\", \"end_positions\"]`.\n",
       "    load_best_model_at_end (`bool`, *optional*, defaults to `False`):\n",
       "        Whether or not to load the best model found during training at the end of training.\n",
       "\n",
       "        <Tip>\n",
       "\n",
       "        When set to `True`, the parameters `save_strategy` needs to be the same as `eval_strategy`, and in the case\n",
       "        it is \"steps\", `save_steps` must be a round multiple of `eval_steps`.\n",
       "\n",
       "        </Tip>\n",
       "\n",
       "    metric_for_best_model (`str`, *optional*):\n",
       "        Use in conjunction with `load_best_model_at_end` to specify the metric to use to compare two different\n",
       "        models. Must be the name of a metric returned by the evaluation with or without the prefix `\"eval_\"`. Will\n",
       "        default to `\"loss\"` if unspecified and `load_best_model_at_end=True` (to use the evaluation loss).\n",
       "\n",
       "        If you set this value, `greater_is_better` will default to `True`. Don't forget to set it to `False` if\n",
       "        your metric is better when lower.\n",
       "    greater_is_better (`bool`, *optional*):\n",
       "        Use in conjunction with `load_best_model_at_end` and `metric_for_best_model` to specify if better models\n",
       "        should have a greater metric or not. Will default to:\n",
       "\n",
       "        - `True` if `metric_for_best_model` is set to a value that isn't `\"loss\"` or `\"eval_loss\"`.\n",
       "        - `False` if `metric_for_best_model` is not set, or set to `\"loss\"` or `\"eval_loss\"`.\n",
       "    ignore_data_skip (`bool`, *optional*, defaults to `False`):\n",
       "        When resuming training, whether or not to skip the epochs and batches to get the data loading at the same\n",
       "        stage as in the previous training. If set to `True`, the training will begin faster (as that skipping step\n",
       "        can take a long time) but will not yield the same results as the interrupted training would have.\n",
       "    sharded_ddp (`bool`, `str` or list of [`~trainer_utils.ShardedDDPOption`], *optional*, defaults to `False`):\n",
       "        Use Sharded DDP training from [FairScale](https://github.com/facebookresearch/fairscale) (in distributed\n",
       "        training only). This is an experimental feature.\n",
       "\n",
       "        A list of options along the following:\n",
       "\n",
       "        - `\"simple\"`: to use first instance of sharded DDP released by fairscale (`ShardedDDP`) similar to ZeRO-2.\n",
       "        - `\"zero_dp_2\"`: to use the second instance of sharded DPP released by fairscale (`FullyShardedDDP`) in\n",
       "          Zero-2 mode (with `reshard_after_forward=False`).\n",
       "        - `\"zero_dp_3\"`: to use the second instance of sharded DPP released by fairscale (`FullyShardedDDP`) in\n",
       "          Zero-3 mode (with `reshard_after_forward=True`).\n",
       "        - `\"offload\"`: to add ZeRO-offload (only compatible with `\"zero_dp_2\"` and `\"zero_dp_3\"`).\n",
       "\n",
       "        If a string is passed, it will be split on space. If a bool is passed, it will be converted to an empty\n",
       "        list for `False` and `[\"simple\"]` for `True`.\n",
       "    deepspeed (`str` or `dict`, *optional*):\n",
       "        Use [Deepspeed](https://github.com/microsoft/deepspeed). This is an experimental feature and its API may\n",
       "        evolve in the future. The value is either the location of DeepSpeed json config file (e.g.,\n",
       "        `ds_config.json`) or an already loaded json file as a `dict`\"\n",
       "    label_smoothing_factor (`float`, *optional*, defaults to 0.0):\n",
       "        The label smoothing factor to use. Zero means no label smoothing, otherwise the underlying onehot-encoded\n",
       "        labels are changed from 0s and 1s to `label_smoothing_factor/num_labels` and `1 - label_smoothing_factor +\n",
       "        label_smoothing_factor/num_labels` respectively.\n",
       "    debug (`str` or list of [`~debug_utils.DebugOption`], *optional*, defaults to `\"\"`):\n",
       "        Enable one or more debug features. This is an experimental feature.\n",
       "\n",
       "        Possible options are:\n",
       "\n",
       "        - `\"underflow_overflow\"`: detects overflow in model's input/outputs and reports the last frames that led to\n",
       "          the event\n",
       "        - `\"tpu_metrics_debug\"`: print debug metrics on TPU\n",
       "\n",
       "        The options should be separated by whitespaces.\n",
       "    optim (`str` or [`training_args.OptimizerNames`], *optional*, defaults to `\"adamw_hf\"`):\n",
       "        The optimizer to use: adamw_hf, adamw_torch, adamw_apex_fused, or adafactor.\n",
       "    adafactor (`bool`, *optional*, defaults to `False`):\n",
       "        This argument is deprecated. Use `--optim adafactor` instead.\n",
       "    group_by_length (`bool`, *optional*, defaults to `False`):\n",
       "        Whether or not to group together samples of roughly the same length in the training dataset (to minimize\n",
       "        padding applied and be more efficient). Only useful if applying dynamic padding.\n",
       "    length_column_name (`str`, *optional*, defaults to `\"length\"`):\n",
       "        Column name for precomputed lengths. If the column exists, grouping by length will use these values rather\n",
       "        than computing them on train startup. Ignored unless `group_by_length` is `True` and the dataset is an\n",
       "        instance of `Dataset`.\n",
       "    report_to (`str` or `List[str]`, *optional*, defaults to `\"all\"`):\n",
       "        The list of integrations to report the results and logs to. Supported platforms are `\"azure_ml\"`,\n",
       "        `\"comet_ml\"`, `\"mlflow\"`, `\"tensorboard\"` and `\"wandb\"`. Use `\"all\"` to report to all integrations\n",
       "        installed, `\"none\"` for no integrations.\n",
       "    ddp_find_unused_parameters (`bool`, *optional*):\n",
       "        When using distributed training, the value of the flag `find_unused_parameters` passed to\n",
       "        `DistributedDataParallel`. Will default to `False` if gradient checkpointing is used, `True` otherwise.\n",
       "    ddp_bucket_cap_mb (`int`, *optional*):\n",
       "        When using distributed training, the value of the flag `bucket_cap_mb` passed to `DistributedDataParallel`.\n",
       "    dataloader_pin_memory (`bool`, *optional*, defaults to `True`):\n",
       "        Whether you want to pin memory in data loaders or not. Will default to `True`.\n",
       "    skip_memory_metrics (`bool`, *optional*, defaults to `True`):\n",
       "        Whether to skip adding of memory profiler reports to metrics. This is skipped by default because it slows\n",
       "        down the training and evaluation speed.\n",
       "    push_to_hub (`bool`, *optional*, defaults to `False`):\n",
       "        Whether or not to push the model to the Hub every time the model is saved. If this is activated,\n",
       "        `output_dir` will begin a git directory synced with the the repo (determined by `hub_model_id`) and the\n",
       "        content will be pushed each time a save is triggered (depending on your `save_strategy`). Calling\n",
       "        [`~Trainer.save_model`] will also trigger a push.\n",
       "\n",
       "        <Tip warning={true}>\n",
       "\n",
       "        If `output_dir` exists, it needs to be a local clone of the repository to which the [`Trainer`] will be\n",
       "        pushed.\n",
       "\n",
       "        </Tip>\n",
       "\n",
       "    resume_from_checkpoint (`str`, *optional*):\n",
       "        The path to a folder with a valid checkpoint for your model. This argument is not directly used by\n",
       "        [`Trainer`], it's intended to be used by your training/evaluation scripts instead. See the [example\n",
       "        scripts](https://github.com/huggingface/transformers/tree/master/examples) for more details.\n",
       "    hub_model_id (`str`, *optional*):\n",
       "        The name of the repository to keep in sync with the local *output_dir*. It can be a simple model ID in\n",
       "        which case the model will be pushed in your namespace. Otherwise it should be the whole repository name,\n",
       "        for instance `\"user_name/model\"`, which allows you to push to an organization you are a member of with\n",
       "        `\"organization_name/model\"`. Will default to `user_name/output_dir_name` with *output_dir_name* being the\n",
       "        name of `output_dir`.\n",
       "\n",
       "        Will default to to the name of `output_dir`.\n",
       "    hub_strategy (`str` or [`~trainer_utils.HubStrategy`], *optional*, defaults to `\"every_save\"`):\n",
       "        Defines the scope of what is pushed to the Hub and when. Possible values are:\n",
       "\n",
       "        - `\"end\"`: push the model, its configuration, the tokenizer (if passed along to the [`Trainer`]) and a\n",
       "          draft of a model card when the [`~Trainer.save_model`] method is called.\n",
       "        - `\"every_save\"`: push the model, its configuration, the tokenizer (if passed along to the [`Trainer`]) and\n",
       "          a draft of a model card each time there is a model save. The pushes are asynchronous to not block\n",
       "          training, and in case the save are very frequent, a new push is only attempted if the previous one is\n",
       "          finished. A last push is made with the final model at the end of training.\n",
       "        - `\"checkpoint\"`: like `\"every_save\"` but the latest checkpoint is also pushed in a subfolder named\n",
       "          last-checkpoint, allowing you to resume training easily with\n",
       "          `trainer.train(resume_from_checkpoint=\"last-checkpoint\")`.\n",
       "        - `\"all_checkpoints\"`: like `\"checkpoint\"` but all checkpoints are pushed like they appear in the output\n",
       "          folder (so you will get one checkpoint folder per folder in your final repository)\n",
       "\n",
       "    hub_token (`str`, *optional*):\n",
       "        The token to use to push the model to the Hub. Will default to the token in the cache folder obtained with\n",
       "        `huggingface-cli login`.\n",
       "    gradient_checkpointing (`bool`, *optional*, defaults to `False`):\n",
       "        If True, use gradient checkpointing to save memory at the expense of slower backward pass.\n",
       "\n",
       "sortish_sampler (`bool`, *optional*, defaults to `False`):\n",
       "    Whether to use a *sortish sampler* or not. Only possible if the underlying datasets are *Seq2SeqDataset* for\n",
       "    now but will become generally available in the near future.\n",
       "\n",
       "    It sorts the inputs according to lengths in order to minimize the padding size, with a bit of randomness for\n",
       "    the training set.\n",
       "predict_with_generate (`bool`, *optional*, defaults to `False`):\n",
       "    Whether to use generate to calculate generative metrics (ROUGE, BLEU).\n",
       "generation_max_length (`int`, *optional*):\n",
       "    The `max_length` to use on each evaluation loop when `predict_with_generate=True`. Will default to the\n",
       "    `max_length` value of the model configuration.\n",
       "generation_num_beams (`int`, *optional*):\n",
       "    The `num_beams` to use on each evaluation loop when `predict_with_generate=True`. Will default to the\n",
       "    `num_beams` value of the model configuration.\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;34m@\u001b[0m\u001b[0mdataclass\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0madd_start_docstrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainingArguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0mSeq2SeqTrainingArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainingArguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m    sortish_sampler (`bool`, *optional*, defaults to `False`):\u001b[0m\n",
       "\u001b[0;34m        Whether to use a *sortish sampler* or not. Only possible if the underlying datasets are *Seq2SeqDataset* for\u001b[0m\n",
       "\u001b[0;34m        now but will become generally available in the near future.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        It sorts the inputs according to lengths in order to minimize the padding size, with a bit of randomness for\u001b[0m\n",
       "\u001b[0;34m        the training set.\u001b[0m\n",
       "\u001b[0;34m    predict_with_generate (`bool`, *optional*, defaults to `False`):\u001b[0m\n",
       "\u001b[0;34m        Whether to use generate to calculate generative metrics (ROUGE, BLEU).\u001b[0m\n",
       "\u001b[0;34m    generation_max_length (`int`, *optional*):\u001b[0m\n",
       "\u001b[0;34m        The `max_length` to use on each evaluation loop when `predict_with_generate=True`. Will default to the\u001b[0m\n",
       "\u001b[0;34m        `max_length` value of the model configuration.\u001b[0m\n",
       "\u001b[0;34m    generation_num_beams (`int`, *optional*):\u001b[0m\n",
       "\u001b[0;34m        The `num_beams` to use on each evaluation loop when `predict_with_generate=True`. Will default to the\u001b[0m\n",
       "\u001b[0;34m        `num_beams` value of the model configuration.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msortish_sampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"help\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Whether to use SortishSampler or not.\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpredict_with_generate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"help\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Whether to use generate to calculate generative metrics (ROUGE, BLEU).\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgeneration_max_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"help\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"The `max_length` to use on each evaluation loop when `predict_with_generate=True`. Will default \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"to the `max_length` value of the model configuration.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgeneration_num_beams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"help\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"The `num_beams` to use on each evaluation loop when `predict_with_generate=True`. Will default \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"to the `num_beams` value of the model configuration.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.9/site-packages/transformers/training_args_seq2seq.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a609b68-7557-4182-94da-dfc0e95b1a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n",
    "# check_min_version(\"4.18.0.dev0\")\n",
    "\n",
    "require_version(\n",
    "    \"datasets>=1.8.0\",\n",
    "    \"To fix: pip install -r examples/pytorch/summarization/requirements.txt\",\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"tokenizers/punkt\")\n",
    "except (LookupError, OSError):\n",
    "    if is_offline_mode():\n",
    "        raise LookupError(\n",
    "            \"Offline mode: run this script without TRANSFORMERS_OFFLINE first to download nltk data files\"\n",
    "        )\n",
    "    with FileLock(\".lock\") as lock:\n",
    "        nltk.download(\"punkt\", quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de409ff2-7d87-4cae-a53d-4872194e9aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: str = field(\n",
    "        metadata={\n",
    "            \"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"\n",
    "        }\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Pretrained config name or path if not the same as model_name\"\n",
    "        },\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Pretrained tokenizer name or path if not the same as model_name\"\n",
    "        },\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Where to store the pretrained models downloaded from huggingface.co\"\n",
    "        },\n",
    "    )\n",
    "    use_fast_tokenizer: bool = field(\n",
    "        default=True,\n",
    "        metadata={\n",
    "            \"help\": \"Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.\"\n",
    "        },\n",
    "    )\n",
    "    model_revision: str = field(\n",
    "        default=\"main\",\n",
    "        metadata={\n",
    "            \"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"\n",
    "        },\n",
    "    )\n",
    "    use_auth_token: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Will use the token generated when running `transformers-cli login` (necessary to use this script \"\n",
    "            \"with private models).\"\n",
    "        },\n",
    "    )\n",
    "    resize_position_embeddings: Optional[bool] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Whether to automatically resize the position embeddings if `max_source_length` exceeds \"\n",
    "            \"the model's position embeddings.\"\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8335f5aa-449a-47ab-a875-836c0eb70de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    \"\"\"\n",
    "\n",
    "    lang: str = field(default=None, metadata={\"help\": \"Language id for summarization.\"})\n",
    "\n",
    "    dataset_name: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"},\n",
    "    )\n",
    "    dataset_config_name: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The configuration name of the dataset to use (via the datasets library).\"\n",
    "        },\n",
    "    )\n",
    "    text_column: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The name of the column in the datasets containing the full texts (for summarization).\"\n",
    "        },\n",
    "    )\n",
    "    summary_column: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The name of the column in the datasets containing the summaries (for summarization).\"\n",
    "        },\n",
    "    )\n",
    "    train_file: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The input training data file (a jsonlines or csv file).\"},\n",
    "    )\n",
    "    validation_file: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"An optional input evaluation data file to evaluate the metrics (rouge) on \"\n",
    "            \"(a jsonlines or csv file).\"\n",
    "        },\n",
    "    )\n",
    "    test_file: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"An optional input test data file to evaluate the metrics (rouge) on \"\n",
    "            \"(a jsonlines or csv file).\"\n",
    "        },\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Overwrite the cached training and evaluation sets\"},\n",
    "    )\n",
    "    preprocessing_num_workers: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n",
    "    )\n",
    "    max_source_length: Optional[int] = field(\n",
    "        default=1024,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated, sequences shorter will be padded.\"\n",
    "        },\n",
    "    )\n",
    "    max_target_length: Optional[int] = field(\n",
    "        default=128,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total sequence length for target text after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated, sequences shorter will be padded.\"\n",
    "        },\n",
    "    )\n",
    "    val_max_target_length: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total sequence length for validation target text after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated, sequences shorter will be padded. Will default to `max_target_length`.\"\n",
    "            \"This argument is also used to override the ``max_length`` param of ``model.generate``, which is used \"\n",
    "            \"during ``evaluate`` and ``predict``.\"\n",
    "        },\n",
    "    )\n",
    "    pad_to_max_length: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Whether to pad all samples to model maximum sentence length. \"\n",
    "            \"If False, will pad the samples dynamically when batching to the maximum length in the batch. More \"\n",
    "            \"efficient on GPU but very bad for TPU.\"\n",
    "        },\n",
    "    )\n",
    "    max_train_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    max_eval_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    max_predict_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    num_beams: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Number of beams to use for evaluation. This argument will be passed to ``model.generate``, \"\n",
    "            \"which is used during ``evaluate`` and ``predict``.\"\n",
    "        },\n",
    "    )\n",
    "    ignore_pad_token_for_loss: bool = field(\n",
    "        default=True,\n",
    "        metadata={\n",
    "            \"help\": \"Whether to ignore the tokens corresponding to padded labels in the loss computation or not.\"\n",
    "        },\n",
    "    )\n",
    "    source_prefix: Optional[str] = field(\n",
    "        default=\"\",\n",
    "        metadata={\n",
    "            \"help\": \"A prefix to add before every source text (useful for T5 models).\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    forced_bos_token: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The token to force as the first generated token after the decoder_start_token_id.\"\n",
    "            \"Useful for multilingual models like mBART where the first generated token\"\n",
    "            \"needs to be the target language token (Usually it is the target language token)\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if (\n",
    "            self.dataset_name is None\n",
    "            and self.train_file is None\n",
    "            and self.validation_file is None\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"Need either a dataset name or a training/validation file.\"\n",
    "            )\n",
    "        else:\n",
    "            if self.train_file is not None:\n",
    "                extension = self.train_file.split(\".\")[-1]\n",
    "                assert extension in [\n",
    "                    \"csv\",\n",
    "                    \"json\",\n",
    "                ], \"`train_file` should be a csv or a json file.\"\n",
    "            if self.validation_file is not None:\n",
    "                extension = self.validation_file.split(\".\")[-1]\n",
    "                assert extension in [\n",
    "                    \"csv\",\n",
    "                    \"json\",\n",
    "                ], \"`validation_file` should be a csv or a json file.\"\n",
    "        if self.val_max_target_length is None:\n",
    "            self.val_max_target_length = self.max_target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "892b4922-edad-4de7-a643-59517934fca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_name_mapping = {\n",
    "    \"amazon_reviews_multi\": (\"review_body\", \"review_title\"),\n",
    "    \"big_patent\": (\"description\", \"abstract\"),\n",
    "    \"cnn_dailymail\": (\"article\", \"highlights\"),\n",
    "    \"orange_sum\": (\"text\", \"summary\"),\n",
    "    \"pn_summary\": (\"article\", \"summary\"),\n",
    "    \"psc\": (\"extract_text\", \"summary_text\"),\n",
    "    \"samsum\": (\"dialogue\", \"summary\"),\n",
    "    \"thaisum\": (\"body\", \"summary\"),\n",
    "    \"xglue\": (\"news_body\", \"news_title\"),\n",
    "    \"xsum\": (\"document\", \"summary\"),\n",
    "    \"wiki_summary\": (\"article\", \"highlights\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4736cc92-7a31-4e46-9efa-ad6ecda64f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755ad0b229d04d719f630dbaa1da1260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dad139bd5e54891ab4f2e399628d055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/954 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xsum/default (download: 245.38 MiB, generated: 507.60 MiB, post-processed: Unknown size, total: 752.98 MiB) to /home/cdsw/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64def481daf499990de57f254ee242c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be138d12d034d32be7801d96b50ae20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7aceb63efe49449cacef69cbb934b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.00M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdfc09b2934495a81c54b9bd5a4924e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcd23d6bf5b45caad610e3cc6b0d71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd96bb725ee490e872d4eeec4e37f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xsum downloaded and prepared to /home/cdsw/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376e79e77b8c4d49bcb171134a47f0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = load_dataset(\"xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "808934e3-387d-46b1-8ae8-727dcbe8cb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 204045\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 11332\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 11334\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82e93947-7008-40fb-9682-218b8d6cf44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnc_datasets_clean = load_from_disk(\"../data/processed/WNC_oneword\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "425f5709-5154-4616-80b3-ab439420f379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    dev: Dataset({\n",
       "        features: ['rev_id', 'source_text', 'target_text'],\n",
       "        num_rows: 671\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['rev_id', 'source_text', 'target_text'],\n",
       "        num_rows: 967\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['rev_id', 'source_text', 'target_text'],\n",
       "        num_rows: 52093\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnc_datasets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e6bee-5fe5-4c83-a3b6-70c7808f5a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "wnc_datasets_clean.pop("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83d9b19f-11ef-44fb-b01d-7ab4f714c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnc_datasets_clean[\"validation\"] = wnc_datasets_clean.pop(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "133030f0-d598-4854-b29e-f98362c2d024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['rev_id', 'source_text', 'target_text'],\n",
       "        num_rows: 967\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['rev_id', 'source_text', 'target_text'],\n",
       "        num_rows: 52093\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['rev_id', 'source_text', 'target_text'],\n",
       "        num_rows: 671\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnc_datasets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "990c6ac8-1fed-4938-a6c8-d73dac214143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # See all possible arguments in src/transformers/training_args.py\n",
    "    # or by passing the --help flag to this script.\n",
    "    # We now keep distinct sets of args, for a cleaner separation of concerns.\n",
    "\n",
    "    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, Seq2SeqTrainingArguments))\n",
    "    if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n",
    "        # If we pass only one argument to the script and it's the path to a json file,\n",
    "        # let's parse it to get our arguments.\n",
    "        model_args, data_args, training_args = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n",
    "    else:\n",
    "        model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "\n",
    "    # Setup logging\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        handlers=[logging.StreamHandler(sys.stdout)],\n",
    "    )\n",
    "    log_level = training_args.get_process_log_level()\n",
    "    logger.setLevel(log_level)\n",
    "    datasets.utils.logging.set_verbosity(log_level)\n",
    "    transformers.utils.logging.set_verbosity(log_level)\n",
    "    transformers.utils.logging.enable_default_handler()\n",
    "    transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "    # Log on each process the small summary:\n",
    "    logger.warning(\n",
    "        f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "        + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    "    )\n",
    "    logger.info(f\"Training/evaluation parameters {training_args}\")\n",
    "\n",
    "    if data_args.source_prefix is None and model_args.model_name_or_path in [\n",
    "        \"t5-small\",\n",
    "        \"t5-base\",\n",
    "        \"t5-large\",\n",
    "        \"t5-3b\",\n",
    "        \"t5-11b\",\n",
    "    ]:\n",
    "        logger.warning(\n",
    "            \"You're running a t5 model but didn't provide a source prefix, which is the expected, e.g. with \"\n",
    "            \"`--source_prefix 'summarize: ' `\"\n",
    "        )\n",
    "\n",
    "    # Detecting last checkpoint.\n",
    "    last_checkpoint = None\n",
    "    if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n",
    "        last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "            raise ValueError(\n",
    "                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "                \"Use --overwrite_output_dir to overcome.\"\n",
    "            )\n",
    "        elif last_checkpoint is not None and training_args.resume_from_checkpoint is None:\n",
    "            logger.info(\n",
    "                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "            )\n",
    "\n",
    "    # Set seed before initializing model.\n",
    "    set_seed(training_args.seed)\n",
    "\n",
    "    # Get the datasets: you can either provide your own CSV/JSON training and evaluation files (see below)\n",
    "    # or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/\n",
    "    # (the dataset will be downloaded automatically from the datasets Hub).\n",
    "    #\n",
    "    # For CSV/JSON files this script will use the first column for the full texts and the second column for the\n",
    "    # summaries (unless you specify column names for this with the `text_column` and `summary_column` arguments).\n",
    "    #\n",
    "    # In distributed training, the load_dataset function guarantee that only one local process can concurrently\n",
    "    # download the dataset.\n",
    "    if data_args.dataset_name is not None:\n",
    "        # Downloading and loading a dataset from the hub.\n",
    "        raw_datasets = load_dataset(\n",
    "            data_args.dataset_name, data_args.dataset_config_name, cache_dir=model_args.cache_dir\n",
    "        )\n",
    "    else:\n",
    "        data_files = {}\n",
    "        if data_args.train_file is not None:\n",
    "            data_files[\"train\"] = data_args.train_file\n",
    "            extension = data_args.train_file.split(\".\")[-1]\n",
    "        if data_args.validation_file is not None:\n",
    "            data_files[\"validation\"] = data_args.validation_file\n",
    "            extension = data_args.validation_file.split(\".\")[-1]\n",
    "        if data_args.test_file is not None:\n",
    "            data_files[\"test\"] = data_args.test_file\n",
    "            extension = data_args.test_file.split(\".\")[-1]\n",
    "        raw_datasets = load_dataset(extension, data_files=data_files, cache_dir=model_args.cache_dir)\n",
    "    # See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at\n",
    "    # https://huggingface.co/docs/datasets/loading_datasets.html.\n",
    "\n",
    "    # Load pretrained model and tokenizer\n",
    "    #\n",
    "    # Distributed training:\n",
    "    # The .from_pretrained methods guarantee that only one local process can concurrently\n",
    "    # download model & vocab.\n",
    "    config = AutoConfig.from_pretrained(\n",
    "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "        revision=model_args.model_revision,\n",
    "        use_auth_token=True if model_args.use_auth_token else None,\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "        use_fast=model_args.use_fast_tokenizer,\n",
    "        revision=model_args.model_revision,\n",
    "        use_auth_token=True if model_args.use_auth_token else None,\n",
    "    )\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
    "        config=config,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "        revision=model_args.model_revision,\n",
    "        use_auth_token=True if model_args.use_auth_token else None,\n",
    "    )\n",
    "\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    if model.config.decoder_start_token_id is None and isinstance(tokenizer, (MBartTokenizer, MBartTokenizerFast)):\n",
    "        if isinstance(tokenizer, MBartTokenizer):\n",
    "            model.config.decoder_start_token_id = tokenizer.lang_code_to_id[data_args.lang]\n",
    "        else:\n",
    "            model.config.decoder_start_token_id = tokenizer.convert_tokens_to_ids(data_args.lang)\n",
    "\n",
    "    if model.config.decoder_start_token_id is None:\n",
    "        raise ValueError(\"Make sure that `config.decoder_start_token_id` is correctly defined\")\n",
    "\n",
    "    if (\n",
    "        hasattr(model.config, \"max_position_embeddings\")\n",
    "        and model.config.max_position_embeddings < data_args.max_source_length\n",
    "    ):\n",
    "        if model_args.resize_position_embeddings is None:\n",
    "            logger.warning(\n",
    "                f\"Increasing the model's number of position embedding vectors from {model.config.max_position_embeddings} \"\n",
    "                f\"to {data_args.max_source_length}.\"\n",
    "            )\n",
    "            model.resize_position_embeddings(data_args.max_source_length)\n",
    "        elif model_args.resize_position_embeddings:\n",
    "            model.resize_position_embeddings(data_args.max_source_length)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"`--max_source_length` is set to {data_args.max_source_length}, but the model only has {model.config.max_position_embeddings}\"\n",
    "                f\" position encodings. Consider either reducing `--max_source_length` to {model.config.max_position_embeddings} or to automatically \"\n",
    "                \"resize the model's position encodings by passing `--resize_position_embeddings`.\"\n",
    "            )\n",
    "\n",
    "    prefix = data_args.source_prefix if data_args.source_prefix is not None else \"\"\n",
    "\n",
    "    # Preprocessing the datasets.\n",
    "    # We need to tokenize inputs and targets.\n",
    "    if training_args.do_train:\n",
    "        column_names = raw_datasets[\"train\"].column_names\n",
    "    elif training_args.do_eval:\n",
    "        column_names = raw_datasets[\"validation\"].column_names\n",
    "    elif training_args.do_predict:\n",
    "        column_names = raw_datasets[\"test\"].column_names\n",
    "    else:\n",
    "        logger.info(\"There is nothing to do. Please pass `do_train`, `do_eval` and/or `do_predict`.\")\n",
    "        return\n",
    "\n",
    "    if isinstance(tokenizer, tuple(MULTILINGUAL_TOKENIZERS)):\n",
    "        assert (\n",
    "            data_args.lang is not None\n",
    "        ), f\"{tokenizer.__class__.__name__} is a multilingual tokenizer which requires --lang argument\"\n",
    "\n",
    "        tokenizer.src_lang = data_args.lang\n",
    "        tokenizer.tgt_lang = data_args.lang\n",
    "\n",
    "        # For multilingual translation models like mBART-50 and M2M100 we need to force the target language token\n",
    "        # as the first generated token. We ask the user to explicitly provide this as --forced_bos_token argument.\n",
    "        forced_bos_token_id = (\n",
    "            tokenizer.lang_code_to_id[data_args.forced_bos_token] if data_args.forced_bos_token is not None else None\n",
    "        )\n",
    "        model.config.forced_bos_token_id = forced_bos_token_id\n",
    "\n",
    "    # Get the column names for input/target.\n",
    "    dataset_columns = summarization_name_mapping.get(data_args.dataset_name, None)\n",
    "    if data_args.text_column is None:\n",
    "        text_column = dataset_columns[0] if dataset_columns is not None else column_names[0]\n",
    "    else:\n",
    "        text_column = data_args.text_column\n",
    "        if text_column not in column_names:\n",
    "            raise ValueError(\n",
    "                f\"--text_column' value '{data_args.text_column}' needs to be one of: {', '.join(column_names)}\"\n",
    "            )\n",
    "    if data_args.summary_column is None:\n",
    "        summary_column = dataset_columns[1] if dataset_columns is not None else column_names[1]\n",
    "    else:\n",
    "        summary_column = data_args.summary_column\n",
    "        if summary_column not in column_names:\n",
    "            raise ValueError(\n",
    "                f\"--summary_column' value '{data_args.summary_column}' needs to be one of: {', '.join(column_names)}\"\n",
    "            )\n",
    "\n",
    "    # Temporarily set max_target_length for training.\n",
    "    max_target_length = data_args.max_target_length\n",
    "    padding = \"max_length\" if data_args.pad_to_max_length else False\n",
    "\n",
    "    if training_args.label_smoothing_factor > 0 and not hasattr(model, \"prepare_decoder_input_ids_from_labels\"):\n",
    "        logger.warning(\n",
    "            \"label_smoothing is enabled but the `prepare_decoder_input_ids_from_labels` method is not defined for\"\n",
    "            f\"`{model.__class__.__name__}`. This will lead to loss being calculated twice and will take up more memory\"\n",
    "        )\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        # remove pairs where at least one record is None\n",
    "\n",
    "        inputs, targets = [], []\n",
    "        for i in range(len(examples[text_column])):\n",
    "            if examples[text_column][i] is not None and examples[summary_column][i] is not None:\n",
    "                inputs.append(examples[text_column][i])\n",
    "                targets.append(examples[summary_column][i])\n",
    "\n",
    "        inputs = [prefix + inp for inp in inputs]\n",
    "        model_inputs = tokenizer(inputs, max_length=data_args.max_source_length, padding=padding, truncation=True)\n",
    "\n",
    "        # Setup the tokenizer for targets\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = tokenizer(targets, max_length=max_target_length, padding=padding, truncation=True)\n",
    "\n",
    "        # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "        # padding in the loss.\n",
    "        if padding == \"max_length\" and data_args.ignore_pad_token_for_loss:\n",
    "            labels[\"input_ids\"] = [\n",
    "                [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "            ]\n",
    "\n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "        return model_inputs\n",
    "\n",
    "    if training_args.do_train:\n",
    "        if \"train\" not in raw_datasets:\n",
    "            raise ValueError(\"--do_train requires a train dataset\")\n",
    "        train_dataset = raw_datasets[\"train\"]\n",
    "        if data_args.max_train_samples is not None:\n",
    "            train_dataset = train_dataset.select(range(data_args.max_train_samples))\n",
    "        with training_args.main_process_first(desc=\"train dataset map pre-processing\"):\n",
    "            train_dataset = train_dataset.map(\n",
    "                preprocess_function,\n",
    "                batched=True,\n",
    "                num_proc=data_args.preprocessing_num_workers,\n",
    "                remove_columns=column_names,\n",
    "                load_from_cache_file=not data_args.overwrite_cache,\n",
    "                desc=\"Running tokenizer on train dataset\",\n",
    "            )\n",
    "\n",
    "    if training_args.do_eval:\n",
    "        max_target_length = data_args.val_max_target_length\n",
    "        if \"validation\" not in raw_datasets:\n",
    "            raise ValueError(\"--do_eval requires a validation dataset\")\n",
    "        eval_dataset = raw_datasets[\"validation\"]\n",
    "        if data_args.max_eval_samples is not None:\n",
    "            eval_dataset = eval_dataset.select(range(data_args.max_eval_samples))\n",
    "        with training_args.main_process_first(desc=\"validation dataset map pre-processing\"):\n",
    "            eval_dataset = eval_dataset.map(\n",
    "                preprocess_function,\n",
    "                batched=True,\n",
    "                num_proc=data_args.preprocessing_num_workers,\n",
    "                remove_columns=column_names,\n",
    "                load_from_cache_file=not data_args.overwrite_cache,\n",
    "                desc=\"Running tokenizer on validation dataset\",\n",
    "            )\n",
    "\n",
    "    if training_args.do_predict:\n",
    "        max_target_length = data_args.val_max_target_length\n",
    "        if \"test\" not in raw_datasets:\n",
    "            raise ValueError(\"--do_predict requires a test dataset\")\n",
    "        predict_dataset = raw_datasets[\"test\"]\n",
    "        if data_args.max_predict_samples is not None:\n",
    "            predict_dataset = predict_dataset.select(range(data_args.max_predict_samples))\n",
    "        with training_args.main_process_first(desc=\"prediction dataset map pre-processing\"):\n",
    "            predict_dataset = predict_dataset.map(\n",
    "                preprocess_function,\n",
    "                batched=True,\n",
    "                num_proc=data_args.preprocessing_num_workers,\n",
    "                remove_columns=column_names,\n",
    "                load_from_cache_file=not data_args.overwrite_cache,\n",
    "                desc=\"Running tokenizer on prediction dataset\",\n",
    "            )\n",
    "\n",
    "    # Data collator\n",
    "    label_pad_token_id = -100 if data_args.ignore_pad_token_for_loss else tokenizer.pad_token_id\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer,\n",
    "        model=model,\n",
    "        label_pad_token_id=label_pad_token_id,\n",
    "        pad_to_multiple_of=8 if training_args.fp16 else None,\n",
    "    )\n",
    "\n",
    "    # Metric\n",
    "    metric = load_metric(\"rouge\")\n",
    "\n",
    "    def postprocess_text(preds, labels):\n",
    "        preds = [pred.strip() for pred in preds]\n",
    "        labels = [label.strip() for label in labels]\n",
    "\n",
    "        # rougeLSum expects newline after each sentence\n",
    "        preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "        labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "        return preds, labels\n",
    "\n",
    "    def compute_metrics(eval_preds):\n",
    "        preds, labels = eval_preds\n",
    "        if isinstance(preds, tuple):\n",
    "            preds = preds[0]\n",
    "        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "        if data_args.ignore_pad_token_for_loss:\n",
    "            # Replace -100 in the labels as we can't decode them.\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        # Some simple post-processing\n",
    "        decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "        result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "        # Extract a few results from ROUGE\n",
    "        result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "\n",
    "        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "        result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "        result = {k: round(v, 4) for k, v in result.items()}\n",
    "        return result\n",
    "\n",
    "    # Initialize our Trainer\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset if training_args.do_train else None,\n",
    "        eval_dataset=eval_dataset if training_args.do_eval else None,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics if training_args.predict_with_generate else None,\n",
    "    )\n",
    "\n",
    "    # Training\n",
    "    if training_args.do_train:\n",
    "        checkpoint = None\n",
    "        if training_args.resume_from_checkpoint is not None:\n",
    "            checkpoint = training_args.resume_from_checkpoint\n",
    "        elif last_checkpoint is not None:\n",
    "            checkpoint = last_checkpoint\n",
    "        train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "        trainer.save_model()  # Saves the tokenizer too for easy upload\n",
    "\n",
    "        metrics = train_result.metrics\n",
    "        max_train_samples = (\n",
    "            data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n",
    "        )\n",
    "        metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n",
    "        trainer.log_metrics(\"train\", metrics)\n",
    "        trainer.save_metrics(\"train\", metrics)\n",
    "        trainer.save_state()\n",
    "\n",
    "    # Evaluation\n",
    "    results = {}\n",
    "    max_length = (\n",
    "        training_args.generation_max_length\n",
    "        if training_args.generation_max_length is not None\n",
    "        else data_args.val_max_target_length\n",
    "    )\n",
    "    num_beams = data_args.num_beams if data_args.num_beams is not None else training_args.generation_num_beams\n",
    "    if training_args.do_eval:\n",
    "        logger.info(\"*** Evaluate ***\")\n",
    "        metrics = trainer.evaluate(max_length=max_length, num_beams=num_beams, metric_key_prefix=\"eval\")\n",
    "        max_eval_samples = data_args.max_eval_samples if data_args.max_eval_samples is not None else len(eval_dataset)\n",
    "        metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n",
    "\n",
    "        trainer.log_metrics(\"eval\", metrics)\n",
    "        trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "    if training_args.do_predict:\n",
    "        logger.info(\"*** Predict ***\")\n",
    "\n",
    "        predict_results = trainer.predict(\n",
    "            predict_dataset, metric_key_prefix=\"predict\", max_length=max_length, num_beams=num_beams\n",
    "        )\n",
    "        metrics = predict_results.metrics\n",
    "        max_predict_samples = (\n",
    "            data_args.max_predict_samples if data_args.max_predict_samples is not None else len(predict_dataset)\n",
    "        )\n",
    "        metrics[\"predict_samples\"] = min(max_predict_samples, len(predict_dataset))\n",
    "\n",
    "        trainer.log_metrics(\"predict\", metrics)\n",
    "        trainer.save_metrics(\"predict\", metrics)\n",
    "\n",
    "        if trainer.is_world_process_zero():\n",
    "            if training_args.predict_with_generate:\n",
    "                predictions = tokenizer.batch_decode(\n",
    "                    predict_results.predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "                )\n",
    "                predictions = [pred.strip() for pred in predictions]\n",
    "                output_prediction_file = os.path.join(training_args.output_dir, \"generated_predictions.txt\")\n",
    "                with open(output_prediction_file, \"w\") as writer:\n",
    "                    writer.write(\"\\n\".join(predictions))\n",
    "\n",
    "    kwargs = {\"finetuned_from\": model_args.model_name_or_path, \"tasks\": \"summarization\"}\n",
    "    if data_args.dataset_name is not None:\n",
    "        kwargs[\"dataset_tags\"] = data_args.dataset_name\n",
    "        if data_args.dataset_config_name is not None:\n",
    "            kwargs[\"dataset_args\"] = data_args.dataset_config_name\n",
    "            kwargs[\"dataset\"] = f\"{data_args.dataset_name} {data_args.dataset_config_name}\"\n",
    "        else:\n",
    "            kwargs[\"dataset\"] = data_args.dataset_name\n",
    "\n",
    "    if data_args.lang is not None:\n",
    "        kwargs[\"language\"] = data_args.lang\n",
    "\n",
    "    if training_args.push_to_hub:\n",
    "        trainer.push_to_hub(**kwargs)\n",
    "    else:\n",
    "        trainer.create_model_card(**kwargs)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ef7cb-cbf3-4a7c-94a1-074f2fb5ce26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1b6c50-8052-495b-b869-51ed99529706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d98d1ab-2749-4e73-9e51-e9a34f65b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_metric("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49397a27-81fc-4052-a4ed-2135cb25cd4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8207bf7f-d0c9-403a-b558-4584f8def016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94774415-7a19-46da-97c6-3a0ebe0f26a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc861b45-c1cb-4ff6-8c6b-7d225f4aab45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865c21d9-a64e-42e2-a9cc-a315caf49c61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
