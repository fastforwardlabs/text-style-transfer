{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12a5873d-7e70-45c4-af1f-cca45462f040",
   "metadata": {},
   "source": [
    "# Style Transfer Intensity (STI)\n",
    "\n",
    "Style Transfer Strength is often evaluated by training a classifier on the labeled dataset and measuring the number of outputes classified as having the target style. \n",
    "\n",
    "[This paper](https://arxiv.org/pdf/1904.02295.pdf) proposes an alternative method.\n",
    "\n",
    "Rather than count how many output texts achieve a target style, we can capture more nuanced differences between the style distributions of x and x', using Earth Mover’s Distance.EMD is the minimum “cost” to turn one distribution into the other, or how “intense” the transfer is. Distributions can have any number of values (styles), so EMD handles binary and non-binary datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba1c4a-1442-47cf-a050-28c40e458163",
   "metadata": {},
   "source": [
    "## Prepare WNC for style classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "731d9d4c-dc0c-4e02-b798-c3fc956363f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from datasets import (\n",
    "    load_dataset,\n",
    "    load_from_disk,\n",
    "    load_metric,\n",
    "    Dataset,\n",
    "    Features,\n",
    "    Value,\n",
    "    ClassLabel,\n",
    "    DatasetDict,\n",
    ")\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f92c9666-64cd-45b4-813f-cc0595bf5322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classification_dataset(path: str) -> DatasetDict:\n",
    "    \"\"\"\n",
    "    Formats the translation-task version of WNC as a classification dataset.\n",
    "\n",
    "    Dataset splits remain the same, but the number of records in each split are doubled\n",
    "    as we create an individual record for both the \"source_text\" and \"target_text\" fields.\n",
    "    In this way, \"source_text\" is assigned a label of \"subjective\" and \"target_text\" is assigned\n",
    "    a label of \"neutral\". Records are randomly shuffled within each split.\n",
    "\n",
    "    Args:\n",
    "        path (str): path to HuggingFace dataset\n",
    "\n",
    "    Returns:\n",
    "        DatasetDict\n",
    "\n",
    "    \"\"\"\n",
    "    datasets = load_from_disk(path)\n",
    "    dataset_dict = defaultdict(dict)\n",
    "\n",
    "    SPLITS = [\"train\", \"test\", \"validation\"]\n",
    "    LABEL_MAPPING = {\"source_text\": \"subjective\", \"target_text\": \"neutral\"}\n",
    "    FEATURES = Features(\n",
    "        {\n",
    "            \"text\": Value(\"string\"),\n",
    "            \"label\": ClassLabel(num_classes=2, names=[\"subjective\", \"neutral\"]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for split in SPLITS:\n",
    "        df = datasets[split].to_pandas()\n",
    "        split_dict = defaultdict(list)\n",
    "\n",
    "        for column, label in LABEL_MAPPING.items():\n",
    "            split_dict[\"text\"].extend(df[column].tolist())\n",
    "            split_dict[\"label\"].extend([label] * len(df))\n",
    "\n",
    "        dataset_dict[split] = Dataset.from_dict(\n",
    "            split_dict, features=FEATURES\n",
    "        )  # .shuffle(seed=42)\n",
    "\n",
    "    return DatasetDict(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e7a4d33-c201-46a9-b48b-e85c7667465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_PATH = \"/home/cdsw/data/processed/WNC_full\"\n",
    "wnc_classification = build_classification_dataset(DATASETS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "555f50ca-fef7-4a3c-ad5c-722d26193b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 308394\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 17154\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 17214\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnc_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e67d3800-35c0-44e3-80d1-c5e4c2d74384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': [\"while for long nearly only women where shown as sex objects, increasing tolerance, more tempered censorship, emancipatory developments and increasing buying power of previously neglected appreciative target groups in rich markets (mainly in the west) have lead to a marked increase in the share of attractive male flesh 'on display'.\",\n",
       "  \"following the end of kenneth kaunda's repressive dictatorship , chiluba won the country's multi-party presidential elections.\",\n",
       "  'a brilliant quarterback with the university of illinois, haller was signed by the giants as an amateur free agent in 1958. he made his debut on april 11, 1961 as a platoon catcher.',\n",
       "  'traitor to his people adam yahiye gadahn (born september 1, 1978) is an american-born man who is suspected of being a member of the al qaeda organization.',\n",
       "  'a funny thing happened on the way to the moon is a 2001 documentary written, produced, and directed by nashville, tennessee-based filmmaker and investigative journalist bart winfield sibrel, a critic of the united states space program and proponent of the unsubstantiated theory that the six apollo lunar landing missions between 1969 and 1972 were hoaxes perpetrated by the us government.',\n",
       "  'the redcliffe forward, originally from roma, queensland, spent four months in france with the tonneins club in 1982-83 before using the state of origin stage to force his way into the australian side against new zealand in 1983. a rugged, no-nonsense back-rower, fullerton smith played in the last two tests against great britain in 1984 before joining english club leeds in the 1984-85 off-season.',\n",
       "  'of course not all universities carry such courses under this label, and neither do they all teach feminist ideology as the sole material in the course.',\n",
       "  \"volatility increased dramatically in bonds, commodities and virtually all asset classes, and the uptick rule only applies to equities, so it's removal was obviously not related to the fall in the markets.\",\n",
       "  'marc morano is the owner and founder of the website climate depot, funded by conservative billionaire richard mellon scaife and a project of the committee for a constructive tomorrow.',\n",
       "  \"although weapons are rarely used in practice, except in advanced training, movements are made 'as if' the opponent was wielding a knife, stick, or one of other numerous weapons (this author does not advocate ' gun ' defense , although techniques do exist, within the context of the system , to address this modern concern ) .\"],\n",
       " 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnc_classification[\"train\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d08fd572-1adc-4304-bcd3-50116727c22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': [\"increased tolerance, more tempered censorship, emancipatory developments and increasing buying power of previously neglected appreciative target groups in rich markets (mainly in the west) have lead to a marked increase in the share of attractive male flesh 'on display'.\",\n",
       "  \"following the end of kenneth kaunda's presidency , chiluba won the country's multi-party presidential elections.\",\n",
       "  'a quarterback with the university of illinois, haller was signed by the giants as an amateur free agent in 1958. he made his debut on april 11, 1961 as a platoon catcher.',\n",
       "  'adam yahiye gadahn (born september 1, 1978) is an american-born man who is suspected of being a member of the al qaeda organization.',\n",
       "  'a funny thing happened on the way to the moon is a 2001 documentary written, produced, and directed by nashville, tennessee-based filmmaker and investigative journalist bart winfield sibrel, a critic of the united states space program and proponent of the theory that the six apollo lunar landing missions between 1969 and 1972 were hoaxes perpetrated by the us government.',\n",
       "  'the redcliffe forward, originally from roma, queensland, spent four months in france with the tonneins club in 1982-83 before using the state of origin stage to force his way into the australian side against new zealand in 1983. fullerton smith played in the last two tests against great britain in 1984 before joining english club leeds in the 1984-85 off-season.',\n",
       "  'not all universities carry such courses under this label, and neither do they all teach feminist ideology as the sole material in the course.',\n",
       "  \"volatility increased dramatically in bonds, commodities and virtually all asset classes, and the uptick rule only applies to equities, so it's removal was arguably not related to the fall in the markets.\",\n",
       "  'marc morano is the owner and founder of the website climate depot, a project of the committee for a constructive tomorrow.',\n",
       "  \"although weapons are rarely used in practice, except in advanced training, movements are made 'as if' the opponent was wielding a knife, stick, or one of other numerous weapons , gun defense techniques do exist, within the context of the system to address this modern concern.\"],\n",
       " 'label': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_half = int(len(wnc_classification[\"train\"]) / 2)\n",
    "wnc_classification[\"train\"][second_half : second_half + 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4231af2-f11e-4247-85a4-5920733d1612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154197.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wnc_classification[\"train\"]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fcdb204-5355-49b8-9832-b8d1ec73918c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308394"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "154197 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d00ab-99fe-4a65-a35c-bb57e1ac44d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1eba95-7749-438e-83b8-270a538606af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31861c9-a3d0-4be2-85cf-21a6c7f7c590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc08d8-715d-4fb2-ba7d-8479ab74be90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9edb5ed-b175-4c5a-bd90-5143c3498951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbda895-bc1d-4687-b052-e23966f978c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b760e8d6-e22c-45b2-8ea2-2f6789ed471c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5e4d6cb-0565-4576-ab23-30d83a06cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "CLS_DATASET_PATH = \"/home/cdsw/data/processed/WNC_full_cls\"\n",
    "# os.makedirs(CLS_DATASET_PATH)\n",
    "# wnc_classification.save_to_disk(CLS_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7a58e4-984c-4af2-909f-2ffea7254331",
   "metadata": {},
   "source": [
    "### Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "090047ab-0ba6-4c43-b3cb-26f24c7b1a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107c88c488ce489eac628bf13562fb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1657932aeab64a6fb4bc1ac7ebc05a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be66dca8f48a460e92d0b5e51a94f8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_wnc_classification = DatasetDict(\n",
    "    {\n",
    "        \"train\": wnc_classification[\"train\"].select(range(1000)),\n",
    "        \"test\": wnc_classification[\"test\"].select(range(1000)),\n",
    "        \"validation\": wnc_classification[\"validation\"].select(range(1000)),\n",
    "    }\n",
    ")\n",
    "\n",
    "TEST_CLS_DATASET_PATH = \"/home/cdsw/data/processed/WNC_full_cls_TEST\"\n",
    "os.makedirs(TEST_CLS_DATASET_PATH)\n",
    "test_wnc_classification.save_to_disk(TEST_CLS_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72556471-c4ed-4246-adab-bb20a4f1b62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_wnc_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f536ac-daf5-4473-8a11-c85c2191e6a5",
   "metadata": {},
   "source": [
    "## Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "903cdbee-1d11-447a-9280-c4b1480f0b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLS_DATASET_PATH = \"/home/cdsw/data/processed/WNC_full_cls_TEST\"\n",
    "wnc_full_cls = load_from_disk(CLS_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad2a170-cd09-4b86-8501-6aec3f1ceaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnc_full_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05fd61f-4fef-4ab7-bafb-ecaca24388e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d4700b4-674a-4f77-9b2e-e3e5fcf72cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from transformers.integrations import MLflowCallback\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f918d8d-cefa-4527-bab5-df00387a7d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_utils import IntervalStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0d33d0f-88f0-4165-bf29-81fb847e0e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/cdsw/data/processed/WNC_full_cls_TEST/train/cache-11a8b3faaf6e3c0a.arrow\n",
      "Loading cached processed dataset at /home/cdsw/data/processed/WNC_full_cls_TEST/test/cache-5c62f87956a8bec2.arrow\n",
      "Loading cached processed dataset at /home/cdsw/data/processed/WNC_full_cls_TEST/validation/cache-8db993456d6202ea.arrow\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = wnc_full_cls.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b35b4152-9949-44cb-9973-749d8a808ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"bert-cls-full\"\n",
    "MODEL_DIR = \"/home/cdsw/models\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.join(MODEL_DIR, MODEL_NAME),\n",
    "    learning_rate=5e-05,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    logging_dir=os.path.join(MODEL_DIR, \"logs\", MODEL_NAME),\n",
    "    logging_steps=50,\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_total_limit=5,\n",
    "    save_steps=100,\n",
    "    # metric_for_best_model=\"f1\",\n",
    "    # greater_is_better=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9bb2536-5611-49b4-890e-d9280aa91d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a5f6eb9-8b96-4db0-98e4-5089c2e8ca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = load_metric(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "148dd7fe-cfe7-41c6-9775-360983186253",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.remove_callback(MLflowCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "929f0f63-a21e-4c2e-9042-e8674b65e04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/cdsw/.local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 315\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [315/315 01:05, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.685300</td>\n",
       "      <td>0.685976</td>\n",
       "      <td>0.581000</td>\n",
       "      <td>0.527621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>0.983388</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.657696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>1.293017</td>\n",
       "      <td>0.622000</td>\n",
       "      <td>0.623506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/cdsw/models/bert-cls-full/checkpoint-100\n",
      "Configuration saved in /home/cdsw/models/bert-cls-full/checkpoint-100/config.json\n",
      "Model weights saved in /home/cdsw/models/bert-cls-full/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /home/cdsw/models/bert-cls-full/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /home/cdsw/models/bert-cls-full/checkpoint-100/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/cdsw/models/bert-cls-full/checkpoint-200\n",
      "Configuration saved in /home/cdsw/models/bert-cls-full/checkpoint-200/config.json\n",
      "Model weights saved in /home/cdsw/models/bert-cls-full/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /home/cdsw/models/bert-cls-full/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /home/cdsw/models/bert-cls-full/checkpoint-200/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/cdsw/models/bert-cls-full/checkpoint-300\n",
      "Configuration saved in /home/cdsw/models/bert-cls-full/checkpoint-300/config.json\n",
      "Model weights saved in /home/cdsw/models/bert-cls-full/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /home/cdsw/models/bert-cls-full/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /home/cdsw/models/bert-cls-full/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/cdsw/models/bert-cls-full/checkpoint-5000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=315, training_loss=0.4158816258112589, metrics={'train_runtime': 65.9758, 'train_samples_per_second': 75.785, 'train_steps_per_second': 4.774, 'total_flos': 194422625470080.0, 'train_loss': 0.4158816258112589, 'epoch': 5.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89de0ea7-ff18-4d52-89a2-10b355e742c9",
   "metadata": {},
   "source": [
    "### Step Through Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e36d3346-0a07-4314-9240-fdf57d491c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_datasets[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7722688-868d-4e76-8349-ad5e8db0b031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3496061, -0.6291089],\n",
       "       [ 1.2544787, -2.2091932],\n",
       "       [ 1.4202304, -2.272884 ],\n",
       "       ...,\n",
       "       [ 1.9655778, -2.7637262],\n",
       "       [-2.3133612,  2.5391092],\n",
       "       [ 1.3082958, -2.4287748]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e975bb74-3a70-4d08-b276-a404f08bed3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74992d71-9d07-4c34-a84d-61e94cbdf70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(predictions.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3cb7665-03e8-49e0-9e9a-b3bf77b0a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"glue\", \"mrpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fc6ba2c-e9f8-4264-8cf0-8da90e5bc6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.626, 'f1': 0.625250501002004}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d6ffadc-7ee3-4103-a597-f2a1886ce067",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-fed3befee4fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-38a3d51cb394>\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(eval_preds)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"glue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mrpc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "compute_metrics(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7619862f-a8a9-4fd2-a379-6f7f5e106773",
   "metadata": {},
   "source": [
    "#### manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cd8e324-7989-48a1-b554-2f34cf669900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0258575422b4e82a822dd705196c189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_metric = load_metric(\"accuracy\")\n",
    "f1_metric = load_metric(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "033ded69-44c1-424c-b3d7-d9d6e3430ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.626}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1d58085-bbe9-4f1e-a891-6758159c03d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.625250501002004}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830a1a01-2e97-4805-a772-bfa9d5b2246c",
   "metadata": {},
   "source": [
    "## Load a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "445a1d3f-efa7-4d82-8be9-3329abb7e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1d5f7a-455c-4617-8750-e066065e2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e4e33b6-d9c6-40a1-8eff-fe01348ccb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"/home/cdsw/models/bert-cls-full3/checkpoint-96000/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd7a9e25-0f25-4f24-89c3-ad34866504d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(task=\"text-classification\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be70789c-2926-4f47-8dd3-7181ffda058e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9783034920692444}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    \"following the end of kenneth kaunda's repressive dictatorship , chiluba won the country's multi-party presidential elections.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "074aa3c1-6afe-4a48-80fb-797367405780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.981116771697998}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    \"following the end of kenneth kaunda's repressive presidency , chiluba won the country's multi-party presidential elections.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d2f99ba-9e95-48a9-bd28-d2d993d33a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text-classification'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ae3e3-e22b-40aa-8325-0b7dd36841cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "279c7d42-a02a-416b-a867-1bf79ece64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b6ae33c-3cea-4b8f-87de-01d7a217f006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'bertscore',\n",
       " 'bleu',\n",
       " 'bleurt',\n",
       " 'cer',\n",
       " 'chrf',\n",
       " 'code_eval',\n",
       " 'comet',\n",
       " 'competition_math',\n",
       " 'coval',\n",
       " 'cuad',\n",
       " 'exact_match',\n",
       " 'f1',\n",
       " 'frugalscore',\n",
       " 'glue',\n",
       " 'google_bleu',\n",
       " 'indic_glue',\n",
       " 'mae',\n",
       " 'mahalanobis',\n",
       " 'matthews_correlation',\n",
       " 'mauve',\n",
       " 'mean_iou',\n",
       " 'meteor',\n",
       " 'mse',\n",
       " 'pearsonr',\n",
       " 'perplexity',\n",
       " 'precision',\n",
       " 'recall',\n",
       " 'roc_auc',\n",
       " 'rouge',\n",
       " 'sacrebleu',\n",
       " 'sari',\n",
       " 'seqeval',\n",
       " 'spearmanr',\n",
       " 'squad',\n",
       " 'squad_v2',\n",
       " 'super_glue',\n",
       " 'ter',\n",
       " 'wer',\n",
       " 'wiki_split',\n",
       " 'xnli',\n",
       " 'xtreme_s']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.list_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "deee98d0-40f4-4736-86e0-b9a870f820c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.training_args.TrainingArguments"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b9f11b1-5913-49d5-9a8c-0cff1e768bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250ae1fe-c614-4a86-8cbd-bfff30ff4ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists('"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e532ed13-46ea-44e6-a8d9-3d9c9860c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from transformers.trainer_utils import IntervalStrategy\n",
    "\n",
    "@dataclass\n",
    "class StiArguments:\n",
    "    \"\"\"\n",
    "    TrainingArguments is the subset of the arguments we use in our example scripts **which relate to the training loop itself**.\n",
    "    Using [`HfArgumentParser`] we can turn this class into [argparse](https://docs.python.org/3/library/argparse#module-argparse) arguments that can be specified on the command line.\n",
    "    \"\"\"\n",
    "    \n",
    "    model_name_or_path: str = field(\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    output_dir: str = field(\n",
    "        metadata={\"help\": \"The output directory where the model predictions and checkpoints will be written.\"},\n",
    "    )\n",
    "    overwrite_output_dir: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"Overwrite the content of the output directory. \"\n",
    "                \"Use this to continue training if output_dir points to a checkpoint directory.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    learning_rate: float = field(default=5e-5, metadata={\"help\": \"The initial learning rate for AdamW.\"})\n",
    "    per_device_train_batch_size: int = field(\n",
    "        default=8, metadata={\"help\": \"Batch size per GPU/TPU core/CPU for training.\"}\n",
    "    )\n",
    "    per_device_eval_batch_size: int = field(\n",
    "        default=8, metadata={\"help\": \"Batch size per GPU/TPU core/CPU for evaluation.\"}\n",
    "    )\n",
    "    num_train_epochs: float = field(default=3.0, metadata={\"help\": \"Total number of training epochs to perform.\"})\n",
    "    logging_dir: Optional[str] = field(default=None, metadata={\"help\": \"Tensorboard log dir.\"})\n",
    "    logging_strategy: IntervalStrategy = field(\n",
    "        default=\"steps\",\n",
    "        metadata={\"help\": \"The logging strategy to use.\"},\n",
    "    )\n",
    "    logging_steps: int = field(default=500, metadata={\"help\": \"Log every X updates steps.\"})\n",
    "    eval_steps: int = field(default=None, metadata={\"help\": \"Run an evaluation every X steps.\"})\n",
    "    evaluation_strategy: IntervalStrategy = field(\n",
    "        default=\"no\",\n",
    "        metadata={\"help\": \"The evaluation strategy to use.\"},\n",
    "    )\n",
    "    save_steps: int = field(default=500, metadata={\"help\": \"Save checkpoint every X updates steps.\"})\n",
    "    save_total_limit: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"Limit the total amount of checkpoints. \"\n",
    "                \"Deletes the older checkpoints in the output_dir. Default is unlimited checkpoints\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    load_best_model_at_end: Optional[bool] = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Whether or not to load the best model found during training at the end of training.\"},\n",
    "    )\n",
    "    metric_for_best_model: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The metric to use to compare two different models.\"}\n",
    "    )\n",
    "    greater_is_better: Optional[bool] = field(\n",
    "        default=None, metadata={\"help\": \"Whether the `metric_for_best_model` should be maximized or not.\"}\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a98874f-7784-41b7-aba7-46640e3ef687",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = HfArgumentParser(StiArguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f96f1fc-ba19-4859-8e30-362fa499bd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HfArgumentParser(prog='ipykernel_launcher.py', usage=None, description=None, formatter_class=<class 'argparse.ArgumentDefaultsHelpFormatter'>, conflict_handler='error', add_help=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca294ef3-5e8d-4197-894f-0928215be4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_action_groups',\n",
       " '_actions',\n",
       " '_add_action',\n",
       " '_add_container_actions',\n",
       " '_add_dataclass_arguments',\n",
       " '_check_conflict',\n",
       " '_check_value',\n",
       " '_defaults',\n",
       " '_get_args',\n",
       " '_get_formatter',\n",
       " '_get_handler',\n",
       " '_get_kwargs',\n",
       " '_get_nargs_pattern',\n",
       " '_get_option_tuples',\n",
       " '_get_optional_actions',\n",
       " '_get_optional_kwargs',\n",
       " '_get_positional_actions',\n",
       " '_get_positional_kwargs',\n",
       " '_get_value',\n",
       " '_get_values',\n",
       " '_handle_conflict_error',\n",
       " '_handle_conflict_resolve',\n",
       " '_has_negative_number_optionals',\n",
       " '_match_argument',\n",
       " '_match_arguments_partial',\n",
       " '_mutually_exclusive_groups',\n",
       " '_negative_number_matcher',\n",
       " '_option_string_actions',\n",
       " '_optionals',\n",
       " '_parse_known_args',\n",
       " '_parse_optional',\n",
       " '_pop_action_class',\n",
       " '_positionals',\n",
       " '_print_message',\n",
       " '_read_args_from_files',\n",
       " '_registries',\n",
       " '_registry_get',\n",
       " '_remove_action',\n",
       " '_subparsers',\n",
       " 'add_argument',\n",
       " 'add_argument_group',\n",
       " 'add_help',\n",
       " 'add_mutually_exclusive_group',\n",
       " 'add_subparsers',\n",
       " 'allow_abbrev',\n",
       " 'argument_default',\n",
       " 'conflict_handler',\n",
       " 'convert_arg_line_to_args',\n",
       " 'dataclass_types',\n",
       " 'description',\n",
       " 'epilog',\n",
       " 'error',\n",
       " 'exit',\n",
       " 'exit_on_error',\n",
       " 'format_help',\n",
       " 'format_usage',\n",
       " 'formatter_class',\n",
       " 'fromfile_prefix_chars',\n",
       " 'get_default',\n",
       " 'parse_args',\n",
       " 'parse_args_into_dataclasses',\n",
       " 'parse_dict',\n",
       " 'parse_intermixed_args',\n",
       " 'parse_json_file',\n",
       " 'parse_known_args',\n",
       " 'parse_known_intermixed_args',\n",
       " 'prefix_chars',\n",
       " 'print_help',\n",
       " 'print_usage',\n",
       " 'prog',\n",
       " 'register',\n",
       " 'set_defaults',\n",
       " 'usage']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06de5ec8-a188-4209-b243-6b4068c659e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f61b7fef-84d4-428e-a5ea-1a85961982fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Script to run train job for seq2seq (TST) or classifier (STI) models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccab520-ac45-43fa-bc06-b03d588805a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0c666-caab-4e63-9160-49f10f0c61fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68b1b58b-88e8-474c-8be4-fea59d52683c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=[], dest='task', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Select which task to run: seq2seq or classifier.', metavar=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('task', type=str, help='Select which task to run: seq2seq or classifier.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d3b8379-6bd8-4426-a148-21615b5efa55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArgumentParser(prog='ipykernel_launcher.py', usage=None, description='Script to run train job for seq2seq (TST) or classifier (STI) models.', formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5595fac-0f48-40ea-8054-3ad6aee84f05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
